# OSI七层模型和四层模型分别是什么？各自功能？

1. 7层模型
   1. 物理层：底层数据传输，传输**原始比特流**。网线、电磁波传输。
   2. 数据链路层：**帧编码**和误差纠正控制。以**帧**的形式传播
   3. 网络层：定义IP，定义路由，进行路由和寻址，以**数据包**的形式传播
   4. 传输层：为两台主机进程间通信提供数据传输服务；TCP/UDP，TCP传输**数据段**、UDP传输**数据报**
   5. 会话层：管理(建立、维护、重连)应用程序之间的会话。以**会话数据**形式传播
   6. 表示层：数据处理(加解密、编解码)。以**数据格式**或**数据表示形式**传播
   7. 应用层：为计算机用户提供服务。以**应用数据**形式传播
2. 4层模型
   
   1. 网络接口层：包括了**物理层**和**数据链路层**。数据帧的发送与接收。
   
   2. 网络层：数据包的路由和转发，实现网络间的通信。IP、ARP、ICMP(互联网控制报文协议)、NAT(网络地址转换协议)、RTP。
   
   3. 传输层：提供端到端的通信服务，确保数据包完整传输。TCP/UDP
   
   4. 应用层：**提供两个终端设备上的应用程序之间信息交换的服务**。HTTP、SSH、DNS、FTP、SMTP(电子邮件传输协议)、POP3/IMAP、RTP。
   
      ![image-20240726163702371](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012009279.png)

第一层的数据叫比特流，第二层的数据叫帧，第三层的数据叫包，第四层的数据叫TCP报文段或UDP用户数据报。

七层的模型是一个标准，而非实现。四层模型是一个实现的应用模型。

## 端口号

系统端口：0-1023 如HTTP(80)、HTTPS(443)、FTP(21、22)、SSH(22)、DNS(53)、STMP(25)
用户端口：1024-49151 注册给特定的一些应用程序。
动态端口：49152-65535用于临时连接。

FTP的21用于控制连接，22端口用于数据传输。


# TCP与UDP

## 1.TCP与UDP的报头

![image-20240726170909125](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012009139.png)

URG：紧急数据标志位 。RST:复位连接，要求立即关闭连接。
PSH：表明当前的数据应该**立即被传递到接收方的应用程序**，而不需要等待更多的TCP段到达。

![image-20240822170713881](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012009664.png)

## 2.TCP和UDP的区别？应用场景？

1. **连接:** TCP是面向连接的，传输数据前要建立连接; UDP不需要连接，即刻传输数据。

2. **服务对象:** TCP是一对一两点服务; UDP支持一对一，一对多，多对多的交互通信。

3. **可靠性:** TCP提供可靠的数据传输，保证数据无差错、不丢失、不重复、按序到达; UDP尽最大努力交付，数据可能丢失、重复或乱序。

4. 拥塞控制、流量控制

    TCP有拥塞控制和流量控制，保证数据传输的安全性。UDP没有，网络拥堵可能导致UDP传输丢包。

5. **首部开销:** TCP首部长度较长，最小20字节，可选40字节; UDP首部只有8字节，固定不变，开销小.

6. **传输方式:** TCP是字节流传输，没有边界;  UDP是一个包一个包发送，有边界。

7. **分片不同**

   若数据大小超过 MSS，TCP在传输层进行分片，接收端在传输层重新组装。如果中途丢失一个分片，只需重传该分片。

   若数据大小超过 MTU，UDP在 IP 层进行分片，接收端在 IP 层组装分片。如果中途丢失一个分片，整个 UDP 数据报将被丢弃。

TCP面向连接，经常用于FTP文件传输、远程登录等，HTTP/HTTPS

UDP一般用于即时通信，比如视频、语音、直播等多媒体通信。

## 3.TCP的缺陷？

1. 升级困难：TCP在内核实现，升级TCP协议只能升级内核，而内核升级比较保守缓慢。
2. 建立连接导致延迟。
3. 队头阻塞：为了保证数据有序，接收方会有队头阻塞，必须等收到前边的数据才能继续接收。
4. 网络迁移需要重新建立TCP连接。

## 4.怎么基于UDP实现可靠传输？

实现可靠性的方法（应用层协议）：

1. 确认应答：接收方接收到数据包后，发送ACK确认，发送方根据ACK判断是否需要重传。
2. 序列号：为每个数据包添加序列号，接收方根据序列号判断数据包的顺序，进行重排序。
3. 超时重传：发送方在发送数据后启动计时器，如果在规定时间内未收到ACK，则进行重传。
4. 流量控制、拥塞控制：控制发送端的发送速率，减少丢包问题。

## 5.说一下KCP？

1. KCP协议概述：
   1. 基于UDP：KCP是在UDP协议之上实现的，利用UDP的简单和快速传输特点，同时引入了TCP的一些可靠传输机制。
   2. 目标：通过减少延迟和提高传输效率，为实时应用（如在线游戏，实时视频等）提供更好的传输性能。
2. 主要功能：
   1. 可靠传输：通过确认机制和重传机制，确保数据包按顺序、完整地到达接收方。
   2. 流量控制：KCP使用滑动窗口和流量控制算法，动态调整发送速率，避免网络拥塞。
   3. 拥塞控制：KCP实现了一种自适应的拥塞控制算法，根据网络状况调整发送窗口大小，优化网络资源利用。
   4. 快速重传：检测到数据包丢失时，KCP可以快速重传丢失的数据包，减少传输延迟。
3. KCP与TCP的区别：
   1. 传输层协议：TCP是内核中的传输层协议，而KCP是基于UDP实现的用户态协议。
   2. 传输效率：KCP通过**减少握手过程**和**拥塞控制的优化**，具有更高的传输效率和更低的延迟。
   3. 实现复杂度：TCP由操作系统管理，而KCP需要在应用层手动理和实现**提供了更灵活的控制和优化空间**。

## 6.TCP的粘包和拆包能说说吗？

TCP粘包：由于TCP是面向流的协议，发送的**数据没有边界**，接收方可能在一次读**取操作中接收到多个发送方的数据包**，导致数据粘在一起。

**解决方法：**

1. 定长消息：每个消息固定长度，接收方按固定长度读取数据。
2. 分隔符：在每个消息之间添加特殊字符作为分隔符，接收方按分隔符拆分数据。
3. 消息头标识长度：在每个数据包前添加一个消息头，消息头包含该数据包的长度，接收方根据长度读取完整消息。

TCP拆包：发送的数据量超过缓冲区(滑动窗口)大小，就会拆分成多次发送。

UDP不会发生粘包问题：UDP具有保护消息边界,在每个UDP包中就有了消息头

## 7.TCP是用来解决什么问题的？

1. 可靠数据传输问题:
   - TCP 提供**无差错传送**、**重传机制**、**顺序控制**等功能,确保数据能够**可靠地从发送端传送到接收端**。
2. 拥塞控制问题:
   - TCP 内置了拥塞控制算法,能够根据网络状况动态**调整发送速率,防止网络过载**, 确保网络资源得到合理利用。
3. 流量控制问题:
   - TCP 使用滑动窗口机制,根据接收端的处理能力动态调整发送速率,防止接收端缓存溢出。
5. 应用层数据流问题:
   - TCP 将应用层的数据流划分为有序的字节流,并提供**缓存**机制,屏蔽了底层数据包的传输细节。

## 8.为什么不在IP层实现控制？

IP层涉及到的设备更多，一条数据在网络上传输需要经过很多设备，设备之间需要靠IP来寻址，**如果IP层实现控制，涉及到的设备就需要关心很多事情，整体传输效率就低了**。每个设备都要检查数据是不是出问题了。所以将控制逻辑独立出TCP这一层。

# TCP三次握手和四次挥手

## 1.TCP的三次握手？

1. 报文头与连接图示
   2. ![image-20240726171720320](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012009243.png)

为了保证客户端和服务器端的可靠连接，TCP建立连接时**必须**要进行三次会话。

1. **客户端发送请求**：客户端生成一个初始序列号 `x`，发送带有 `SYN` 标志的包给服务器，请求建立连接，并进入 `SYN-SENT` 状态。
2. **服务器回应请求**：服务器收到 `SYN` 包后，生成一个初始序列号 `y`，并发送带有 `SYN-ACK` 标志的包给客户端，确认收到请求，并进入 `SYN-RECEIVED` 状态。
3. **客户端确认连接**：客户端收到 `SYN-ACK` 包后，发送一个 `ACK` 包确认服务器的响应。此时，客户端和服务器都进入 `ESTABLISHED` 状态，连接建立成功，可以开始数据传输。

## 2.TCP的握手为什么要是三次，不能是两次吗？

三次握手的必要性在于确保连接的可靠性和一致性。

1. **防止旧连接误启动**：两次握手可能导致旧的连接请求（因网络延迟滞留的 `SYN` 包，不是重传的）被误认为是新的连接请求，从而引发连接状态的混乱。三次握手通过最后一次确认，确保客户端能够验证是否是新的有效连接。
2. **同步序列号**：序列号对可靠传输至关重要。三次握手可以确保双方的初始序列号得到可靠的同步。
3. **避免资源浪费**：通过三次握手，避免旧的连接请求造成服务器资源的浪费。


## 3.TCP第二次握手丢了会怎样？

1. 客户端会重传 SYN 报文(**序列号不变**)，也就是第一次握手，最大重传次数由  tcp_syn_retries 内核参数决定；
2. 服务端会重传 SYN-ACK 报⽂，也就是第二次握⼿，最大重传次数由  tcp_synack_retries 内核参数决定。

## 4.第三次握手丢了会怎样？

服务端会触发超时重传机制，重传 SYN-ACK 报⽂，直到收到第三次握手， 或者达到最大重传次数。

 **注意，ACK 报文是不会有重传的，当 ACK 丢失了，就由对方重传对应的报文。**

## 5.初始序列号ISN怎么取值的？

1. 在三次握手中，客户端和服务端基于时间戳随机生成isn，以确保每个连接的初始序号不同。

2. ISN = M + F。M根据时钟生成，`F` 是通过源和目的 IP 及端口的哈希值（通常使用 MD5 算法）计算得到

   isn不一样：为了防止历史报文被下一个相同四元组的连接接收。

## 6.SYN超时了怎么处理？

1. 重传(一般重传5次)
2. 增加重传间隔时间(每次超时时间是上次的2倍)
3. 多次重传失败就放弃，记录连接失败信息

## 7.什么情况下SYN报文会被丢弃

1. 半连接队列满了。
2. 开启了 `tcp_tw_recycle` 参数，并且在 NAT 环境下，造成 SYN 报文被丢弃。`tcp_tw_recycle` 是一个用于**加速 TCP 端口重用**的机制。它通过监控**时间戳递增性**来确保重用连接是安全的，这样可以快速释放 TIME_WAIT 状态下的资源。但在 NAT 环境下，由于不同设备的时间戳可能不一致，可能会导致连接丢失或失败

## 8.SYN Flood攻击听说过吗？

服务端收到SYN报文会创建半连接对象，存放到内核的半连接队列（哈希表结构），队列满了就无法响应连接请求了。

服务端接收到 ACK 报文后，从「 SYN 队列」取出⼀个半连接对象，然后创建⼀个新的连接对象放入到「 Accept 队列」(全连接队列，链表结构)；

1. 什么是SYN Flood？(一种DDos攻击)

   攻击者通过大量发送 SYN 报文（连接请求）使目标服务器分配资源等待 ACK 报文（确认）。然而，攻击者不发送 ACK，而是继续发送大量 SYN 报文，导致服务器资源被占用，形成大量**半开放连接**，使服务器无法响应正常用户的连接请求。

2. 怎么防止SYN Flood攻击？

   1. 配置 SYN Cookie 机制,可以在不使用SYN 半连接队列的情况下成功建立连接，相当于绕过了 SYN 半连接来建立连接。
      1. SYN队列满了之后，不会丢弃，根据算法算出一个cookie值，将它放到第二次握手报文的序列号里发出第二次握手，第三次握手直接放到连接队列中
   2. 调大TCP半连接队列。
   3. 过滤网关防护。

## 9.TCP的四次挥手？

1. ![image-20240726222523578](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410071812157.png)
   
2. 客户端发送FIN 报⽂， 之后客户端进⼊ FIN_WAIT_1 状态。

3. 服务器回复 `ACK`，进入 `CLOSE_WAIT` 状态；客户端收到后进入 `FIN_WAIT_2` 状态。

4. 服务器处理完数据后，发送 `FIN` 报文，进入 `LAST_ACK` 状态。

5. 客户端收到 `FIN` 后回复 `ACK`，进入 `TIME_WAIT` 状态。

6. 服务器收到 `ACK` 后，进入 `CLOSE` 状态，完成关闭。

7. 客户端在 `TIME_WAIT` 状态下等待 2MSL 后，进入 `CLOSE` 状态，关闭完成。

   主动关闭连接的，才有 TIME_WAIT 状态。

## 10.为什么要四次挥手？挥手一定要四次吗？

服务端通常需要先完成数据处理和发送，因此 ACK 和 FIN 通常分开发送，导致需要四次挥手。

如果被动关闭方「没有数据要发送」且「未开启 TCP_QUICKACK」（即使用默认的 TCP 延迟确认机制），第二次和第三次挥手可能会合并，从而变为三次挥手。

## 11.第一次挥手丢失会怎样？第二次挥手丢失会怎样？

1. 第一次挥手丢失会超时重传，重传次数达到默认之后就直接关闭。
2. 服务端的第二次挥手丢失了，客户端就会触发超时重传机制，重传 FIN 报文，直到收到服务端的第二次挥手，或者达到最大的重传次数，直接关闭。

## 12.第三次挥手丢失会怎样？第四次挥手丢失会怎样？

1. 服务端发送 `FIN` 后未收到 `ACK`，会超时重传，重试多次后强制关闭。客户端如果未收到 `FIN`，会在 `FIN_WAIT_2` 状态下等待，超时后自动关闭。（Close函数关闭）
2. 服务端未收到 `ACK` 确认，会超时重传`FIN`，到最大次数就关闭连接。客户端收到`FIN`进入 `TIME_WAIT` 状态，等待 2MSL。如果再次收到 `FIN`，将重置定时器，等待期满后关闭连接。

## 13.为什么要有TIME_WAIT

1. **防止旧连接数据干扰**：`TIME_WAIT` 确保旧连接的数据包在 2MSL 内被丢弃，避免它们被新连接误接收。
2. **确保连接优雅关闭**：`TIME_WAIT` 确保客户端在第四次挥手丢失时能够重新接收 `FIN` 并发送 `ACK`，防止服务端因 `RST` 而导致非优雅的关闭。

## 14.为什么客户端的 TIME-WAIT 状态必须等待 2MSL ？

1. linux中MSL（报文最大生存时间）是30秒。

2. **确保数据包安全传递**：等待 2MSL 确保在网络中可能存在的延迟或丢失的报文能有足够时间来回传递，确保连接彻底关闭，避免旧报文干扰新连接。

## 15.等待2MSL会产生什么问题？

1. **客户端端口资源占用**：若 `TIME_WAIT` 状态过多，占满了所有端口资源，客户端可能**无法再次连接到相同 `IP + PORT` 的服务端。**
2. **服务端资源消耗**：虽然服务端不会因 `TIME_WAIT` 状态导致端口耗尽，但**大量连接会占用系统资源**，如文件描述符、内存、CPU 和线程资源。

## 16.如何解决2MSL产生的问题？

1. 服务端尽量不要主动断开连接，让客户端承担TIME_WAIT的时间。
2. 复用处于TIME_WAIT的socket被新的连接使用。通过设置 SO_REUSEADDR 套接字选项,可以使得应用程序可以重用处于 TIME_WAIT 状态的端口。

## 17.服务端出现大量TIME_WAIT状态的原因？

1. HTTP没有使用长连接：不使用长连接，服务端就会主动关闭连接。

2. HTTP长连接超时： keepalive_timeout 参数指定了长连接超时时间，如果超时，服务端会关闭连接。

3. HTTP长连接的请求数量达到上限：长连接处理的请求数达到限制时，服务端关闭连接，进入 TIME_WAIT 状态。(keepalive_requests参数)


## 18.shutdown和close关于FIN_WAIT2 状态的区别。

1. **close**：关闭连接时，无法再发送和接收数据，进入 FIN_WAIT2 状态后，`tcp_fin_timeout` 控制连接的持续时间（默认 60 秒）。超过此时间未收到 FIN 报文，连接会被强制关闭。
2. **shutdown**：如果只关闭发送方向，接收方向仍然打开，意味着仍可接收数据。如果未收到第三次挥手，连接会一直保持在 FIN_WAIT2 状态。

## 19.TCP长连接是如何维持的？什么是心跳机制，如果一直想要连接着怎么办？

1. 心跳机制和保活机制。设置定时器，定期发送心跳包，保持连接活跃。
2. 请求数量达到上限。keepalive_requests 参数调大点。

## 20.服务端出现大量ClOSE_WAIT状态的原因？

当服务端出现大量 CLOSE_WAIT 状态的连接的时候，说明服务端的程序没有调用close函数关闭连接。一般问题出现在代码层次：

1. 某些操作（如IO操作、数据库查询等）可能长时间阻塞，导致连接一直处于 **CLOSE_WAIT** 状态，直到阻塞操作完成并且连接被显式关闭。
4. 忘记调用 `close`，或在 `close` 之前代码卡住（如死锁）。

## 21.TCP的ClOSE_WAIT状态能收到报文吗？

在CLOSE_WAIT状态下，仍然可以接收数据。TCP连接在接收到FIN包并回复ACK包后，仍然可以接收数据，直到应用层调用close()关闭连接。

## 22.已经建立了连接，客户端出现故障宕机了，怎么办？服务端进程崩溃了，怎么办？

TCP的**保活机制**或者**应用层心跳机制**可以保证客户端宕机后释放连接。

1. TCP有保活机制：服务端在长时间无活动时发送探测报文，如果多次无响应，服务端会释放连接。9次探测

3. TCP保活的时间太长，在应用层可以实现心跳机制，通过设置短周期的心跳检测（如 HTTP 的 `keepalive_timeout`），更快地检测并释放宕机后的连接。

TCP连接信息由内核维护，服务端进程崩溃，由内核回收其TCP资源，所以可以完成TCP四次挥手。

## 24.建立连接的TCP，收到SYN会发生什么？

1. 端口号与历史连接不一样

   重新建立连接，旧连接超过一段时间会被服务端释放(TCP保活)。

2. 端口号与历史连接相同

   服务端会回复一个Challenge ACK，其中序列号和确认号是旧连接中的，客户端收到发现不是想要的，就会发送RST终止连接。

## 25.两台服务器之间可以同时建立多条TCP链接吗？怎么实现的？

可以。四元组中的一个不同就可以建立新的TCP连接。

## 26.除了四次挥手，还有什么方法断开连接吗？

1.RST标志，发送带有RST标志的TCP报文，可以立即断开连接。

2.超时：连接一段时间内没有数据包传输，双发可以设定超时时间自动断开连接。

# 序列号机制、流量控制、拥塞控制、超时重传、快速重传

## 1.什么是TCP的序列号机制?

1. 序列号(标识数据流中的每个字节)：标识每个 TCP 数据包的顺序，确保数据按正确顺序组装。
2. 确认号：表示接收方期望接收的下一个数据包的序列号，用于确认已接收到的数据。

序列号机制的作用：

1. **数据包排序**：接收方使用序列号按顺序重组数据，即使数据包乱序到达。
2. **丢包检测：**通过确认号，发送方可检测丢包并重传，确保可靠传输。

## 2.TCP的超时重传机制是为了解决什么问题？超时重传时间怎么确定？

超时重传报文的序列号不会变。

1. 数据包丢失。数据包丢失，没有收到接收方的确认包，就需要重新发送。
2. 数据包延迟。因为延迟太长，没有收到确认包就重传。
3. 应答包丢失。接收方的应答包丢失，由发送方重传。

RTO（超时重传时间）是一个略大于RTT的动态变化的数。如果未收到ACK，在RTO超时时间到达后重传数据包，并重新启动计时器

```shell
RTP = μ * SRTT + ∂ * DevRTT
SRTT = SRTT + α（RTT - SRTT） 平滑往返时间 初始化=RTT
DevRTT = (1-β)*DevRTT + β(|RTT - SRTT|) RTT偏差 0.5RTT
α = 0.125，β = 0.25, μ = 1，∂ = 4。
```

## 3.为什么需要快速重传机制？

①超时触发重传存在问题：超时周期可能相对较长.快速重传不以时间为驱动，而是以数据驱动重传。②快速重传的工作方式是当收到三个相同的 ACK 报文时，会在定时器过期之前，重传丢失的报文段。快速重传解决了超时时间的问题。

## 4.SACK的引入是为了解决什么问题？

问题：快速重传是要重传一个，还是要重传后边的所有。

SACK：选择性确认。在TCP头部字段加入SACK，**将已收到的数据信息发送给发送方**。就可以只重传丢失的数据。ACK值小于SACK的值。

双方都要支持SACK，通过net.ipv4.tcp_sack参数打开。默认打开的。

## 5.D-SACK是什么东西？

使用了 SACK 来告诉「发送方」有哪些数据被重复接收了。ACK值大于SACK的值。

ACK丢失、数据包延迟触发超时重传，接收方收到了重复的数据，就会**用SACK通知发送方自己收到了重复的数据。**

## 6.滑动窗口的作用是什么？

为每个数据包确认应答的缺点：包的往返时间越长，通信的效率就越低。

1. 提高传输效率：允许发送方在未收到ACK的情况下发送多个数据包；是等待每个数据包的确认。
2. 实现流量控制：接收方通过调整窗口大小来通知发送方其当前的处理能力。流量控制可以避免发送方的数据填满接收方的缓存，导致缓冲区溢出。
3. 累积确认：接收方可以通过一个ACK报文确认其之前收到的所有数据。

当接收方可用窗口变为0时，发送方实际上会定时发送窗口探测报文，以便知道接收方的窗口是否发生了改变。一般探测三次。

## 7.流量控制

通过**接收窗口**动态调整发送方的数据发送速率，确保接收方的缓冲区不会溢出。核心是**滑动窗口协议**，它通过 TCP 报文中的窗口大小字段实现对发送方的流量控制。

## 8.有了滑动窗口，为什么还要拥塞控制？

1. 拥塞控制是为了避免「发送方」的数据填满整个网络。

2. 拥塞窗口是发送方维护的一个状态变量，根据网络的拥塞程度动态变化。发送窗口 = min(接收窗口， 拥塞窗口)。发送方没有在规定时间内接收到ACK应答报文(发生了超时重传)，就会认为网络出现了拥塞。

## 9.说说拥塞控制的步骤？有哪些拥塞控制算法？(TCP Reno)

1. 慢启动(指数增加)

   一点一点提高发送数据包的数量。发送方每收到一个ACK，拥塞窗口大小就加1.拥塞窗口大于等于慢启动门限(ssthresh)，就使用拥塞避免算法。

2. 拥塞避免

   一般慢启动门限（ssthresh）是65535字节，每收到一个ACK，拥塞窗口增加1/cwnd。变成了线性增长。等到出现丢包触发重传机制，就进入拥塞发生算法。

3. 拥塞发生

   1. 超时重传

      慢启动门限= 拥塞窗口/2; 拥塞窗口恢复初始值。Linux是10.

      然后就重新开始慢启动，突然减少数据流，这种反应比较强烈，会有网络卡顿。

   2. 快速重传

      触发快速重传：拥塞窗口= 拥塞窗口/2; 慢启动门限= 拥塞窗口，进入快速恢复算法。

4. 快速恢复

   拥塞窗口 = 慢启动门限 + 3；重传丢失的数据包，后面收到重复的ACK时，拥塞窗口会加1，收到新数据的ACK，拥塞窗口=慢启动门限。进入拥塞避免。

## 9.1 还知道其他拥塞控制算法吗？

BBR（瓶颈带宽和往返时延）：核心是实时估计网络的**瓶颈带宽**和**往返时延（RTT）**，通过这两项关键参数来确定最佳的发送速率。

过程：

1. **探测带宽（Startup）**：

   在初始阶段，BBR 类似于慢启动，快速增加数据发送速率，直到检测到带宽达到瓶颈为止。此时它会根据 ACK 的反馈调整数据传输速率，避免网络过载。

2. **探测 RTT（RTT Probe）**：

   BBR 会定期降低发送速率，以探测最小 RTT。这一阶段允许 BBR 更新其对最小 RTT 的估计值，确保在网络状况变化时可以及时调整发送速率。

3. **拥塞避免（Drain）**：

   当检测到带宽达到瓶颈时，BBR 会暂时减少发送速率，允许网络清除任何潜在的队列积压，以确保延迟保持在较低水平。

4. **稳态（Steady State）**：

   经过初步的探测后，BBR 会进入稳态，在该阶段它会以接近瓶颈带宽的速率发送数据，同时保持对 RTT 的监控。这个阶段允许 BBR 保持高效的数据传输，同时避免过多的数据积压在网络中。

## 10.拥塞控制在实际生产环境中的问题？

1. 网络带宽与延迟不匹配

   由于 TCP 使用慢启动算法进行拥塞控制，它在初始阶段会慢慢提高传输速率，直到发现网络的带宽限制。这种情况下，带宽很大但延迟很高时，TCP 的慢启动可能在很长时间内无法充分利用网络的实际带宽。

   **解决方案：**使用新型的拥塞控制算法，例如 **BBR（Bottleneck Bandwidth and Round-trip Time）**，它根据带宽和延迟实时调整传输速率，而不是像传统的 TCP Reno 或 TCP CUBIC 那样依赖丢包来判断网络拥塞。**TCP CUBIC 的拥塞控制采用了立方曲线增长方式，使得在高带宽延迟产品的网络中更加高效。**

2. 丢包与网络延迟的矛盾

   在无线网络或不稳定的网络环境中，偶发的丢包并不意味着网络拥塞。如果算法将这些丢包误认为是网络拥塞，传输速率将被不必要地降低，导致带宽利用率低下和传输效率低。

   **解决方案**：结合丢包和延迟两个信号来动态调整拥塞窗口。

3. 突发性流量导致的拥塞

   突发性流量会导致网络设备的缓冲区迅速填满，造成丢包和高延迟。拥塞控制的慢启动反应过慢，无法及时应对这种瞬间激增的流量。可以在缓冲区即将满时随机丢包来预防拥塞。

4. 网络拥塞的公平性问题

   **不公平的带宽分配**：某些连接占用大部分带宽，而其他连接几乎无法获得足够的资源。

## 11.TCP的nagle算法，nagle会带来什么坏处？

Nagle为了避免发送方发送小数据。

Nagle算法的思路是延时处理，只有满足下面两个条件中的任意一个条件，才可以发送数据。(会缓存小的数据包，可能造成粘包)

1. 窗口大小>= MSS, 且数据大小>= MSS；
2. 收到之前发送数据的ACK回包；

接收方要避免通告小窗口，不然接收方ACK回复快，满足条件2，也会发送小数据。窗口大小 <  min(MSS, 缓存空间/2)，就当做窗口为0。

以太网的MTU(网络包的最大长度)，MSS是MTU除去IP头部和TCP头部的长度。

坏处：

1. 增加延迟：在实时性要求高的应用中，如在线游戏、即时通讯等，Nagle算法的延迟会影响用户体验。
2. 应用场景选择：根据应用需求，可以选择关闭Nagle算法，通过在 Socket 设置TCP_NODELAY选项来禁用。

## 12.你怎么保证UDP下帧与帧间的有序性？

**(1)序列号机制：**

1. 发送方：在发送数据包时，为每个数据包添加一个唯一的序列号。序列号从0开始，每发送一个数据包序列号加1。
2. 接收方：接收到数据包后，检查序列号，以确定数据包的顺序。如果数据包按序到达，则将其交给应用层处理；如果数据包乱序到达，则将其存入重排序缓冲区，等待缺失的数据包到达后再按序处理。

**(2)重排序缓冲区：**

**接收方：**维护一个重排序缓冲区，用于缓存乱序到达的数据包。接收方会检查数据包的序列号，将其插入到正确的位置。如果发现有缺失的数据包，则等待缺失的数据包到达后再按序处理。

**(3)ACK确认机制：**

**接收方：**在接收到数据包后，发送一个ACK确认包给发送方，包含已成功接收的最高序列号。发送方根据ACK确认包判断哪些数据包已被接收，哪些数据包需要重传。

**(4)丢包重传机制：**

**发送方：**如果在一定时间内没有收到接收方的ACK确认包，则认为数据包可能丢失，发送方会重传未确认的数据包，以确保接收方能够接收到所有的数据包。

## 13.linux内核收包流程？

1. 网卡接收到从网络传来的数据包，并将其存储在网卡的接收缓冲区中。
2. 网卡通过DMA（Direct Memory Access）将数据包直接传输到系统内存中，避免CPU参与数据传输，提高效率。
3. 网卡通过PCIe总线生成硬件中断，通知CPU有数据包到达，CPU通过桥接/内存控制器接收中断信号。
4. CPU响应中断，执行硬件中断处理程序，硬件中断处理程序触发软中断（NET_RX_SOFTIRQ），软中断处理程序继续处理数据包。
5. 软中断处理程序将数据包从内存缓冲区（RingBUF）中取出，保存到skb（socket buffer）
6. 内核网络协议栈进一步处理数据包，将其放入对应socket的接收队列中（data被放到socket接收队列）。
7. 内核唤醒等待数据的用户进程，用户进程（通过系统调用）从socket接收队列中读取数据进行处理。

# 网络层(IP)

## IP协议作用

定义数据包的格式，对数据包进行路由和寻址，以便他们可以跨网络传播并到达正确的目的地。IPv4 是32位，IPv6是128位。

## IP分类

![img](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012009698.png)

## 公网IP和私网IP的区别？

1. **分配方式不同**：公网地址由互联网注册机构分配，而私网地址由局域网管理员自行分配。
2. **使用范围不同**：公网地址用于Internet上的设备，私网地址用于局域网内部的设备。
3. **唯一性和可达性不同**：公网地址具有全球唯一性和全球可达性，而私网地址只在局域网内部唯一，不具有全球可达性。
4. **转发方式不**同：公网地址可以直接访问Internet上的其他设备，而私网地址需要通过路由器进行转发才能访问Internet上的其他设设备。

## 1.为什么IP可以分片，TCP层还需要MSS呢？

IP分片丢失，整个IP报文的所有分片都得重传。TCP的分片不用重发所有的数据。

## 2.什么是MTU？如何处理MTU的问题？

**MTU**是指网络层协议数据包在数据链路层的最大传输字节数。典型值为1500字节（以太网）。

数据包大于MTU要分片，增加开销。小于MTU会增加数据包数量，增加网络负担

1. **路径 MTU 发现**：动态确认路径上的最小的MTU，避免分片。依赖于 ICMP 消息。
2. **手动调整 MTU**：根据网络情况手动设置合适的 MTU 值。
3. **MSS调整**：在 TCP 中通过设置 MSS 来确保数据段大小不超过 MTU，以避免分片。

## 3.ARP和RARP分别是什么？有什么区别？

2.  ARP（地址解析协议）将 IP 地址解析为 MAC 地址，用于主机间通信。
2.  RARP（逆地址解析协议）将 MAC 地址解析为 IP 地址，通常用于无 IP 地址的设备获取 IP 地址。

## 4.ARP攻击有哪些形式？

1. **ARP 欺骗(ARP Spoofing)**:攻击者发送伪造的 ARP 响应，将自己的 MAC 地址与目标 IP 地址绑定，从而截获或篡改网络流量。
2. **ARP 洪泛(ARP Flooding)**:攻击者发送大量伪造的 ARP 请求或响应，导致网络设备的 **ARP 缓存溢出**，影响正常通信。
3. **ARP 缓存污染(ARP Cache Poisoning)**: 攻击者通过伪造的 ARP 响应包，污染目标主机的 ARP 缓存，使其缓存错误的 IP-MAC 映射，从而影响通信

## 5.如何防止ARP攻击？

1. **静态ARP表：**在网络设备上手动设置固定的IP地址和MAC地址映射，防止ARP欺骗。
2. **交换机端口安全：**启用交换机的端口安全功能，限制每个端口可以学习的MAC地址数量，防止ARP 洪泛
3. 网络入侵检测系统（NIDS）：使用NIDS实时监控网络流量，检测和防止网络中的ARP攻击。

## 6.什么是NAT，有什么作用?

网络地址转换（NAT）：在路由器或防火墙上，将私有网络地址转换为公有网络地址，允许多个设备共享一个公有IP地址。

1. **解决IPv4地址耗尽问题：**通过地址转换，多个设备共享一个公有IP地址，缓解IPv4地址短缺。
2. **提高网络安全性：**隐藏内部网络结构，防止外部攻击。

分类：具体取决于如何处理 IP 地址和端口的转换。

 1. **全锥形 NAT (Full Cone NAT)**

    内部设备的 IP 和端口号通过 NAT 转换为公共 IP 和固定的端口号。**穿透性强**：通常较容易进行 NAT 穿透。

2. **限制锥形 NAT (Restricted Cone NAT)**

   内部设备可以与外部通信，但只有**特定的外部 IP 地址**可以向内部设备发送数据，且需要内部设备先发起通信。**安全性更强**：允许更多控制和限制外部连接。

3. **端口限制锥形 NAT (Port Restricted Cone NAT)**

   与限制锥形 NAT 类似，但它进一步限制外部设备只能从**特定的端口号**发送数据。**限制性更强**：外部设备要通信的条件更苛刻。

4. **对称 NAT (Symmetric NAT)**

   每次从内部网络发出的请求都会被分配一个独立的公共 IP 和端口对。这意味着同一个内部设备与不同的外部设备通信时，会有不同的映射。**最难穿透**：对等连接如 P2P 和 WebRTC 需要额外的 NAT 穿透技术，如 STUN 或 TURN。

## 7.什么是ICMP，作用是什么？

ICMP（Internet Control Message Protocol，互联网控制消息协议）是一种网络层协议，用于在 IP 主机和路由器之间传递**控制消息**和**错误报告**。

**错误报告：**网络不可达、时间超时、参数问题(IP 头部字段错误)、重定向(改用更好的路径)等。

网络诊断：**Ping**：测试主机连通性。**Traceroute**：跟踪数据包经过的路由路径。

## 8.本机向本机发送请求，IP填127.0.0.1和网卡IP地址有区别吗？

1. **127.0.0.1**：数据包在内核网络栈中处理，不经过物理网卡，直接通过回环接口返回。适用于本地通信和测试，不消耗网络带宽。
2. **网卡IP地址**：数据包通过内核网络栈处理，并经过物理网卡发送和接收，走完整的网络路径。用于正常的网络通信，会在网络上产生负载。

# DNS

## 1.一次完整的HTTP请求过程包含哪些内容？

1. DNS域名解析。
2. TCP3次握手
3. 建立TCP连接后发起http请求
4. 服务器响应HTTP请求，浏览器得到html代码
5. 浏览器解析html代码，并请求html代码中的资源。
6. 浏览器对页面进行渲染呈现给用户。

## 2.DNS域名系统

DNS(域名管理系统)，解决的是域名和IP地址的映射问题。DNS是应用层协议，基于UDP，端口是53. (在传统的DNS协议中，UDP数据包的大小默认限制为512字节)

1. 浏览器缓存-系统缓存-DNS缓存。本地有个hosts列表(系统缓存)，先查看域名是否在hosts列表中，如果不在就使用DNS服务查询。

2. DNS服务器层级

   1. 根DNS服务器：提供顶级域服务器的IP地址。
   2. 顶级域DNS服务器：后缀是com、edu、cn等。提供权威DNS服务器的IP地址。
   3. 权威DNS服务器：在因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的 DNS 记录，这些记录将这些主机的名字映射为 IP 地址。
   4. 本地DNS服务器。互联网服务提供商都有本地DNS。起代理作用，转发DNS请求。

3. 请求流程(递归)

   1. 请求本地DNS服务器：本地DNS查缓存，没有就问根服务器。
   2. 根服务器根据后缀提供顶级DNS服务器的IP地址。本地DNS问顶级DNS服务器。
   3. 顶级DNS根据域名提供权威DNS服务器IP地址；本地DNS问权威DNS服务器。
   4. 权威DNS找到ip地址发给本地DNS，本地DNS发给请求主机。

   本地DNS通常缓存了很多顶级DNS服务器的IP地址，一般无需访问根服务器。
   
   还可以迭代解析：本地DNS不是自己向其他DNS服务器进行查询，而是提供根DNS服务器、顶级DNS服务器、权威DNS服务器的IP地址，让主机自己去查。

## 3.DNS负载均衡是什么策略？

**DNS负载均衡技术**可以有效分散负载。其原理是在DNS服务器中为同一域名配置多个IP地址，在应答DNS查询时，它会返回不同的IP地址，将用户的访问请求引导到不同的服务器，从而实现负载均衡。例如，可以根据每台服务器的当前负载、与用户地理位置的距离等因素动态调整解析结果。

## 4.DNS区域传送为什么用TCP？

1. 区域传送是指从一个DNS服务器向另一个DNS服务器复制DNS数据库的一部分或全部内容的过程。目的是确保多个DNS服务器之间的数据一致性。
2. 用TCP协议传输。因为可靠且传输内容大。

#  HTTP/HTTPS

## 5.什么是HTTP协议？常见的状态码有哪些？

HTTP是超文本传输协议，是可以在两点之间传输文字、图片、音视频等超文本数据的约定和规范。

1xx表示目前是协议处理的**中间状态**，还需要后续的操作。
2xx表示**成功**，报文被收到并被正确处理。
3xx表示**重定向**，资源位置发生变动，需要客户端重新发送请求。
4xx表示**客户端错误**，请求报文有误，服务器无法处理。
5xx表示**服务器错误**，服务器在处理请求时内部发生了错误。

200：请求成功;
301：永久重定向; 302: 临时重定向：暂时需要用另一个URL 来访问； 304: 表示资源未修改，重定向已存在的资源文件，也称缓存重定向。303状态码：“查看其他位置”，通常用于重定向，建议客户端用GET请求访问新的URL。
401：未授权。403：禁止访问。404：资源在服务器上不存在或未找到; 405: 请求方法类型不支持;
500：服务器内部出错。502：网关错误。503: 服务端繁忙。504：网关超时。

## 6.HTTP请求方法有哪些？报文有哪些主要首部字段？

1. GET：请求指定页面信息，返回实体主体

2. POST：用于将数据发送到服务器，以创建或更新资源

3. HEAD：返回的响应中没有具体内容

4. OPTIONS：用于获取服务器针对特定资源所支持的通信选项或功能。

5. PUT：用于**上传资源**到服务器，或者**更新服务器上已有的资源**

6. DELETE：请求服务端删除指定的页面。

   ![image-20240828222803907](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010045.png)

   ![image-20240912160326275](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010909.png)

   请求报文：请求行、请求头部(If-Modified-Since)、请求实体

   响应报文：状态行、响应头部(Last-Modified、ETag)、响应实体

   ### 首部字段

   http缓存常用的：

   1. If-None-Match(请求头部):比较Etag变没变。
   2. Etag(响应头部) ：
   3. If-Modified-Since(请求头部)
   4. Last-Modified(响应头部)

   请求

   **Host**: 指定请求的主机名和端口号。

   **Content-Type**: 指定请求体的媒体类型，通常用于 POST 请求。

   **Content-Length**: 指定请求体的长度（以字节为单位）。

   **Cookie**: 用于向服务器发送存储在客户端的 Cookie。

   响应：

   **Content-Type**: 指定响应体的媒体类型。

   **Content-Length**: 指定响应体的长度（以字节为单位）。

   **Cache-Control**: 指定缓存机制的指令，例如 `no-cache`、`max-age` 等。

   **Set-Cookie**: 用于向客户端设置 Cookie。

   **Location**: 在进行重定向时，指定新的 URL。

   **Server**: 提供关于服务器的信息，例如软件名称和版本。

## 7.GET与POST的区别？

GET 的语义是请求获取指定的资源。GET方法是安全、幂等、可被缓存的。
POST 的语义是根据请求负荷(报文主体)对指定的资源做出处理，具体的处理方式视资源类型而不同。POST 不安全，不幂等，(大部分实现)不可缓存。

## 7.1 GET方法参数写法是固定的吗？

GET的参数在？后，用&分割；可以自己约定参数的写法，在服务端能解析到就行

## 7.2 **GET比Post更安全吗？**

从传输的角度来说，http是明文传输，都不安全。GET请求数据在URL上，不太安全，POST数据在HTTP包体内，相对安全。

## 7.3 POST方法会产生两个TCP数据包？

HTTP协议没有明确规定POST会产生两个数据包，在Chrome测试中，不会将header和body分开发送，所以分开发送是部分浏览器的行为，不是必然行为。

## 7.4 POST和PUT

`POST` 通常用于**创建新资源**，而 `PUT` 常用于**更新已有资源**。此外，`POST` 是非幂等的，而 `PUT` 是幂等的（即多次执行相同的 `PUT` 操作会产生相同的结果）。

## 8.TCP 的 Keepalive 和 HTTP 的 Keep-Alive 是一个东西吗？

1. HTTP的Keep-Alive是应用层实现，称为HTTP长连接；TCP的Keepalive是内核态实现的，称为TCP的保活机制。
2. HTTP长连接是指不提出断开连接就保持TCP连接。有keep_alivetime参数，60秒没有新请求，触发回调释放连接。
3. TCP 保活机制可以在双方没有数据交互的情况，通过探测报文，来确定对方的 TCP 连接是否存活，在内核完成。使用设置套接字的SO_KEEPALIVE

## 9. HTTP长连接和短连接的区别？

http报文中长连接是Connection: keep-alive

在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。而从HTTP/1.1起，默认使用长连接，用以保持连接特性。

短连接适用于简单的、请求数量少的场景。长连接更适合现代网页和应用程序，因为它们通常需要加载多个资源。可以显著减少延迟，提高性能。

## HTTP1.0介绍

1. HTTP1.0使用短连接，是单一的单一请求/响应模式，每次关闭TCP连接。
2. HTTP1.0的缓存机制使用Expires响应头实现，比较简单。

## 10.HTTP1.1的缺点？

1. 无状态：无状态可以减轻服务器的负担，但是没有记忆能力，难以完成关联操作。解决方案是加Cookie。通过在请求和响应报文中写入Cookie信息来控制客户端的状态。
2. 明文传输：导致抓包的内容可以直接看，没有隐私。
3. 不安全：不验证通信方身份，可能遭遇伪装；无法证明报文的完整性，可能遭到篡改。

## 11.HTTP1.1相比HTTP1.0的改进？

1. 长连接：减少了短连接重复建立和断开造成的额外开销。
2. 支持管道(pipeline)网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。
3. 增加了HOST头，用于标识请求主机。
4. 缓存控制引入了Cache-Control字段，更灵活，分为强制缓存和协商缓存。

HTTP1.1解决了请求的队头阻塞，但是没有解决响应的队头阻塞。默认不开启管道。

**HTTP/1.1 的 HTTP 连接数**：通常为 4-6 个并发连接（针对同一主机）。

##  12. HTTP/2 相⽐ HTTP/1.1 性能上的改进：

1. 头部压缩：通过 HPACK 压缩算法，减少了头部信息的冗余传输，提高了传输效率。(HPACK用到了静态表、动态表、霍夫曼编码，字段用索引表示)
2. 二进制帧传输：采用二进制格式而不是文本格式，减少了解析复杂性，并提高了传输效率。(Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 头部和包体，⼀个 Frame 可以由多个 TCP 报文构成)
3. 多路复用：支持在单一TCP连接上建立多个Stream，从而实现并发多个请求和响应(同一个HTTP的请求和响应在一个stream中)，解决了 HTTP/1.1 中的队头阻塞问题，提高了资源加载速度。(stream可以设置优先级)
4. 服务端推送：允许服务器主动向客户端推送可能需要的静态资源，减少了延迟。

## 13.HTTP2的缺陷？

①队头阻塞；②TCP 与 TLS 的握手延迟；③网络迁移需要重新连接；

## 14.HTTP3相对HTTP2的改进

TCP的重传和按序机制会导致队头阻塞。

HTTP/3 不再依赖 TCP，而是基于 QUIC协议。QUIC 是基于 UDP 的传输层协议，提供类似于 TCP 的可靠性和流控制，但具备更低的连接建立延迟和更好的性能。

1. 连接建立速度更快：QUIC 协议支持 1-RTT（零往返时间）连接建立，显著减少了延迟。
2. 无队头阻塞：在 HTTP/2 中，虽然实现了多路复用，但由于 TCP 层的队头阻塞问题，仍可能导致性能下降。QUIC 协议的多路复用是基于数据包的独立传输，因此避免了 TCP 的队头阻塞问题，即使某个数据包丢失，也不会影响其他数据包的传输。
3. 更好的网络迁移支持：QUIC 协议支持连接的无缝迁移，允许在网络环境变化时保持连接，避免重新建立连接的开销(连接ID)。
4. 内置的加密支持：QUIC 协议默认启用加密，所有数据在传输过程中都是加密的，增强了安全性，减少了复杂性。

## 14.HTTP与HTTPS的区别？

HTTPS是为了解决HTTP不安全的缺陷。在HTTP和TCP之间加入了SSL/TLS安全协议，使报文可以加密传输。

1. HTTP 信息是明文传输，存在安全风险的问题。在HTTP和TCP之间加入了SSL/TLS安全协议，使报文可以加密传输。
2. HTTPS经过TCP连接需要再进行SSL/TLS握手。
3. HTTPS需要向CA申请数字证书来保证服务器的身份可信。
4. HTTP端口是80，HTTPS是443.

## 14.1怎么理解SSL/TLS安全协议？

三个功能：防止窃听(加密)、防止篡改(HMAC)、验证身份，防止冒充(数字证书)。

分为两层：

1. 握手协议：TLS四次握手，协商加密算法和生成对称密钥。
2. 记录协议：负责消息的压缩、数据认证(HMAC)、加密。

## 14.2 SSL和TLS有什么区别？

**TLS 是对 SSL 的改进**：TLS 1.0 作为 SSL 3.0 的升级版本。TLS 保留了 SSL 的许多设计理念，但增强了加密和安全机制。

加密与握手过程

1. SSL 和 TLS 在记录层加密上有细微差别。例如，TLS 在加密哈希函数的设计上更复杂，使用了 HMAC（哈希消息认证码）代替了 SSL 中的 MAC（消息认证码），增强了数据完整性。
2. TLS 1.3 引入了 0-RTT 机制，使得在某些情况下可以在第一轮握手时就发送数据，从而减少初始连接延迟
3. TLS 允许使用更强的加密算法，如 AES 和 SHA-256，而 SSL 的加密算法选择较少且过时。

## 15.HTTPS采用的加密方式是什么？

对称加密+非对称加密：通信建立前采用非对称加密交换会话秘钥，通信过程中使用对称加密。

### 对称加密和非对称加密

1. 对称秘钥加密  优点：运算速度快。缺点：密钥必须保密，无法安全的将秘钥传输给通信方。
2. 非对称加密：非对称加密使用两个密钥:公钥和私钥，公钥可以任意分发而私钥保密，解决了密钥交换问题 但速度慢。公钥加密，私钥解密。

非对称加密的效率低主要是由于其复杂的数学运算（大数模运算、椭圆曲线运算）以及较长的密钥长度。而对称加密算法更为简单、密钥较短、运算效率高，并且可以得到硬件加速的支持。

非对称加密通常仅用于小数据量的加密（如密钥交换、身份验证），而对称加密则用于大数据量的加密（如文件和通信加密）。

在实际应用中，两者经常结合使用，非对称加密用于安全地交换对称密钥，然后用对称加密加密大数据。

## 16.HTTPS的改进(解决的问题)？

1.明文传输。2.验证身份，防伪装。3.确保报文的完整性，防篡改。

1. 使用混合加密解决明文传输的问题。

2. HMAC实现完整性，用对称秘钥和hash算法生成mac(消息认证码)，用于解决篡改风险。

   HMAC是将对称密钥和消息数据通过两次哈希运算得到的，是唯一的消息认证码。(记录协议)

3. 数字证书解决冒充风险。

   数字证书：解决身份伪装，公私钥是可以伪造的。用数字证书确保公钥的身份。

   1.服务器将公钥注册到CA。2.数字证书有 公钥、用途、有效时间等信息。CA将这些信息打包计算出hash值，然后用CA私钥加密得到数字签名，最后颁发数字证书。3.客户端拿到服务端的数字证书，用CA的公钥确认数字证书的真实性。4.使用服务端公钥加密报文。5.服务端使用私钥解密。

   数字证书有 公钥、用途、有效时间等信息。CA将这些信息打包计算出hash值，然后用CA私钥加密得到数字签名。 验证的时候用CA的公钥解密数字签名得到hash值，与自己计算的hash值进行比较。

数字签名：私钥加密，公钥解密。一般是对hash值进行验证。

## 17.HTTPS的TLS四次握手(RSA)

1. 客户端产生随机数C，发送TLS版本号、密码套件列表

2. 服务端回应ACK，回复生成的随机数S，确认TLS版本号，选择密码套件(RSA),发送服务端的数字证书

3. 客户端回应ACK，解析数字证书，使用服务端公钥加密新的随机数Pre-master发送给服务端。发送信号，表示之后使用会话秘钥来加密通信。将之前的信息打包用会话秘钥加密做个验证。

   使用两个随机数和Pre-master就可以生成对称密钥了。

4. 服务端收到之后计算出对称加密，进行会话秘钥加密认证，完成握手。

注意：随机数的交换使用了非对称加密，公钥加密，私钥解密。随机数C和S会与其他握手数据（例如 Pre-master Secret）一起通过 PRF（伪随机函数）生成最终的会话密钥。C和S是公开的，只是为了增加随机性。只有Pre-master是用非对称加密过的。

## 17.2HTTS的TLS的四次握手(ECDHE 椭圆曲线) TLS1.3

使用不同的**密钥交换算法**，握手流程不一样。有RSA和ECDHE

![image-20240901161937307](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010811.png)

b是真数，i是对数。a和p公开，i能得到b，b很难计算i。将i作为私钥，b作为公钥。双方交换公钥，用对方的公钥^自己的私钥 mod p可以得到K，K就是会话秘钥

DHE：随机生成私钥。

ECDHE：在DHE基础上使用ECC椭圆曲线。①双方随机生成ECDHE私钥，椭圆曲线和基点G公开。②ECDHE公钥 = 基点*私钥。③双方交换ECDHE公钥，用自己的ECDHE私钥 * 对方的ECDHE公钥，得到计算点(x, y)，椭圆曲线满足乘法交换和结合律，双方的x相同，x作为会话秘钥。

**第一次握手**：客户端发送TLS版本号、密码套件列表、客户端随机数.

**第二次握手**：服务端确认TLS版本号、选择密码套件、服务端随机数、发送CA证书、选择椭圆曲线、发送服务端ECDHE公钥(用RSA签名，用服务端私钥加密)。(密码套件：秘钥协商使用ECDHE，签名算法用RSA)

**第三次握手**：客户端校验证书，用公钥解密服务端的ECDHE公钥，发送客户端ECDHE公钥，计算出对称密钥。发送finished消息用对称秘钥加密，让服务端做验证。

**第四次握手**：服务端也发送finished消息让客户端校验一下，双方校验没问题就可以用对称密钥了。

对称密钥：x + 服务端随机数 + 客户端随机数。 

客户端可以在TLS握手的早期阶段（甚至在第四次握手之前）发送加密的HTTP数据，从而显著减少延迟并提高通信效率。

## 18.ECDHE相对RSA的优点？

1. 前向保密性。ECDHE 每次握手都生成一个新的临时密钥对（即每个会话使用不同的密钥），会话结束后，这些密钥会被丢弃。RSA 握手中的加密依赖服务端的长期密钥（私钥）。如果服务端的私钥被泄露，攻击者可以通过解密历史上的所有会话来获取会话的对称密钥，从而解密所有传输的数据。这是 RSA 握手的一个重要安全弱点。
2. ECDHE 采用的是**椭圆曲线 Diffie-Hellman** 算法，它基于数学问题的难度，具有较高的安全性和效率。RSA 的安全性依赖于 **大整数分解问题**，随着计算能力的提高和量子计算机的发展，RSA 加密可能面临更大的安全威胁。
3. 性能：使用较短的椭圆曲线密钥（如 256 位）可以达到 RSA 2048 位密钥的安全性水平，性能更好。

## 19.HTTP缓存机制

强制缓存和协商缓存。

![image-20240814204803663](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010119.png)

先检查强制缓存：依靠Cach-Control实现，Cach-Control是一个相对时间，其中设置了过期时间大小。 Cache-Control: max-age=3600。过期了再用协商缓存

协商缓存：

①请求头部的If-None-Match和响应头部的Etag实现：当资源过期，浏览器发现之前响应头中有Etag，再发起请求的时候会将If-None-Match设为Etag值。服务端收到后比较，如果资源没变，就返回304(缓存重定向)。

②请求头部If-Modified-Since和响应头部的Last-Modified实现。当资源过期，浏览器发现之前的响应头中有Last-Modified，再发起请求的时候会将带上Last-Modified的时间。服务端收到请求发现If-Modified-Since，则将它的值与被请求资源的最后修改时间对比，如果资源没变，就返回304，如果变了就返回新资源。

Etag优先级高。过期了发送新的，没过期继续用缓存。

怎么保证缓存是最新的？协商缓存

## 20.HTTP怎么减少重定向请求？

重定向会增加http请求的次数，可以将重定向交给代理服务器解决。重定向的工作交由代理服务器完成，就能减少 HTTP 请求次数了。

![image-20240915150812629](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010820.png)

## Cookie

HTTP是无状态的，HTTP1.1引入了Cookie保存状态信息，**让HTTP协议能够在不同的请求之间保持状态**，使得服务器可以识别客户端的身份，从而实现登录会话管理、个性化服务等功能。

服务器会生成一个包含状态信息的Cookie，比如用户的登录状态、会话ID等。然后通过HTTP响应头中的`Set-Cookie`字段将Cookie发送给客户端。客户端（通常是浏览器）接收到服务器的Cookie后，会将其保存下来，通常是以键值对的形式存储在本地。在后续的请求中，客户端会自动将存储的Cookie通过HTTP请求头中的`Cookie`字段发送给服务器。服务器收到这些Cookie后，就可以通过解析其中的信息来识别用户，并维持请求之间的状态。

缺点：①Cookie存储在客户端，不安全。②每次携带会增加网络带宽。

## Session

将用户信息通过Session存储在服务端，信息更安全。客户端登录完成，服务端会创建对应的Session对象，通过`Set-Cookie`头部将session id发送到客户端，客户端将它存在`Cookie`中，每次再访问服务器，就会再带着Session id，找到之前的Session对象。 
优点：Session更安全、数据容量大，不受Cookie限制、生命周期由服务器控制。

## Session和Cookie的区别？

1. 用户信息存储位置不同：cookie在客户端存储、session在服务端存储
2. 存储数据类型不同：cookie像变量，value是字符串；session是key-value结构，它的value是个对象类型。
3. 存储数据大小不同：cookie受浏览器限制，一般为4k；session受内存限制
4. 生命周期控制：cookie的生命周期累计，从创建开始；session的生命周期是间隔的，指定时间段没访问就会销毁。

### 分布式情况下的session会存在什么问题？

在多个应用服务器之间存储session会话状态时，**保持会话的一致性变得困难**。如果用户的请求被路由到不同的服务器，可能导致无法访问到相同的会话数据，为解决这个问题，一般将会话数据存储在缓存系统（如 Redis）中，确保所有服务器都能访问。

## Token

token也类似一个令牌，无状态，用户信息都被加密到token中，服务器收到token后解密就可知道是哪个用户，需要开发者手动添加。

JWT Token是一种用于身份验证和授权的安全令牌，包含了用户的信息和数字签名，可以在多个系统间共享。

###  JWT的作用：

JWT 最常见的用途是**身份验证**。在用户登录成功后，服务器会生成一个 JWT，并将其返回给客户端。客户端随后可以在后续的请求中使用这个令牌来证明其身份，这种方式不需要在服务器上存储会话状态，避免了分布式情况下会话数据需要共享的问题，因为 JWT 本身包含了用户的信息和验证信息。

### 接收方如何验证JWT的真实性和完整性？

JWT由三部分组成：头部(Header)、载荷(Payload)和签名(Signature)。其中:

- 头部包含类型（通常是 JWT）和使用的签名算法（如 HMAC SHA256）。
- 载荷包含用户可识别的信息和声明（如用户 ID、权限、过期时间等）。
- 签名由头部和载荷的 JSON 字符串生成的签名。

将头部和载荷部分使用相同的编码方法（通常是 Base64 URL 编码），拼接成一个字符串，使用签名算法和密钥对这个字符串进行签名，生成新的签名。
将新生成的签名与 JWT 中的签名部分进行比较。如果这两者匹配，则证明 JWT 的真实性和完整性，即令牌未被篡改。

即使签名验证通过，接收方还需要检查载荷中的有效性信息：过期时间、颁发者、受众、自定义的声明(权限)。(这些信息在载荷中)

## 21.什么是WebSocket？

WebSocket 是一种基于 TCP 连接的全双工通信协议，即客户端和服务器可以同时发送和接收数据。WebSocket 协议本质上是应用层的协议，用于**弥补 HTTP 协议在持久通信能力上的不足**。

客户端和服务器仅需一次握手，两者之间就直接可以创建**持久性的连接**，并进行双向数据传输。

WebSocket的应用场景：视频弹幕、实时消息推送、需要服务器和客户端（浏览器）频繁交互的大部分场景，比如网页游戏，网页聊天室，以及一些类似飞书这样的网页协同办公软件。

## 22.HTTP与WebSocket的区别？

**全双工和半双工**：TCP 协议本身是全双工的，但我们最常用的 HTTP/1.1，虽然是基于 TCP 的协议，但它是**半双工**的，对于大部分需要服务器主动推送数据到客户端的场景，都不太友好，因此我们需要使用支持全双工的 WebSocket 协议。

**应用场景区别**：在 HTTP/1.1 里，只要客户端不问，服务端就不答。基于这样的特点，对于登录页面这样的简单场景，可以使用**定时轮询或者长轮询**的方式实现**服务器推送**(comet)的效果。对于客户端和服务端之间需要频繁交互的复杂场景，比如网页游戏，都可以考虑使用 WebSocket 协议。

## 23. 怎么建立WebSocket连接？

客户端请求连接：客户端（如浏览器或应用程序）通过 WebSocket API 向服务器发送连接请求。这通常包含一个特殊的 HTTP 请求（握手请求），请求头中包含必要的 WebSocket 信息。

![image-20240915153216543](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010217.png)

服务器响应确认：服务器接收到连接请求后，检查请求的有效性。如果请求合法，服务器会回复一个 HTTP 101 状态码，表示协议切换成功。此时，HTTP 连接升级为 WebSocket 连接。

建立双向通信：一旦连接建立，客户端和服务器之间可以开始双向通信。双方都可以随时发送和接收消息，直到连接关闭。（数据包在WebSocket中被叫做帧）

监听和处理事件：在连接期间，双方应当能够处理连接事件（如打开、关闭和错误），以确保通信的稳定性和可靠性。

关闭连接：任何一方都可以主动关闭连接，通常通过发送关闭帧的方式。连接关闭后，双方不再能够通过该连接发送消息。

## 24.为什么有了HTTP还需要WebSocket？

WebSocket 提供了**低延迟、双向、长连接**的实时通信机制，解决了 HTTP 请求-响应模型的局限性，因此在需要高频、实时交互的场景中比 HTTP 更适用。

1. 通信模式不同：

   **HTTP** 是**请求-响应**模型，通信是单向的，客户端需要不断发起新请求才能获取新数据。

   **WebSocket** 是**全双工通信**，客户端和服务器可以在同一连接上同时发送和接收消息。适合实时、连续的数据交换。

2. 连接方式不同：

   **HTTP** 每次请求都会重新创建连接（长连接有超时时间）。

   **WebSocket** 连接一旦建立，保持连接状态直到显式关闭。

3. 高效的数据传输

   WebSocket 连接建立后，数据以帧（frame）的形式在客户端和服务器之间传输。相比于 HTTP 每次请求都包含完整的头部信息WebSocket 减少了传输开销，提升了传输效率。(WebSocket 数据帧格式中包含操作码(opcode)和负载数据(payload)，这使得数据传输更加高效) 

## 25.WebSocket的缺点？

1. 复杂性增加：WebSocket 的握手协议和维护长连接的机制比简单的 HTTP 请求更复杂，开发和调试的难度较大。
2. 资源占用： WebSocket 需要保持长连接，服务器为每个客户端维护一个连接，随着连接数的增加，服务器资源（如内存和处理能力）的占用会迅速增加。
3. 防火墙和代理问题：某些防火墙和代理服务器可能不支持或阻止 WebSocket 协议，可能导致连接失败或者需要额外的配置和支持。

## 26.Socket 和 WebSocket 的区别？

1. **协议层面**

     WebSocket 是基于 **应用层** 的协议，它建立在 **TCP** 之上。WebSocket 是专门为 **全双工通信** 设计的网络协议，允许客户端与服务器之间建立持久的双向连接。

    Socket 是在 **传输层** 使用的编程接口，通常用于基于 **TCP** 或 **UDP** 协议的网络通信。Socket 并不是一种协议，而是编程接口，通过它可以使用各种网络协议进行通信，如 TCP/IP 协议栈。

2. **通信模式**
    **WebSocket**是 **全双工** 模型，这意味着服务器和客户端都可以在连接建立后主动发送消息，不需要等待对方请求或响应。WebSocket 使得持续数据交换更加高效，尤其是在需要实时数据传输的应用中。

    **Socket** 本身是双向的，它可以用于双向通信，但需要实现应用层的协议来定义数据格式和通信规则。

3. **协议复杂度**

    **WebSocket**：提供了一个高层次的抽象，使得双向通信变得简单。它建立连接后，开发者可以直接在 API 层发送和接收消息，而无需管理底层的 TCP 连接状态和数据传输细节。
    **Socket**：提供了低层次的控制，开发者可以决定如何处理数据的发送和接收、连接的建立和关闭、错误处理。

4. **使用场景**

    **WebSocket**适用于需要 **实时数据传输** 的 Web 应用，例如在线聊天、实时游戏、股票行情推送、在线协作工具等。WebSocket 常见于 **浏览器和服务器** 之间的持久双向通信。

    **Socket**是通用的通信机制，广泛用于多种网络编程场景。比如，开发者可以使用 TCP Socket 实现 HTTP 服务器，也可以使用 UDP Socket 实现视频流传输、即时消息等。Socket 的灵活性使其适用于各种应用层协议。

## 27.既然有了HTTP协议，为什么还需要RPC呢？



# Socket

![image-20240901112524777](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010558.png)

## 0.socket在客户端和服务器的创建区别？

1. 客户端通过 `connect()` 主动发起连接，而服务器则通过 `bind()`、`listen()` 和 `accept()` 来被动等待连接。
2. 服务器使用 `socket()` 创建一个监听 Socket 来等待连接。当客户端连接时，服务器创建一个新的 Socket 用于与该客户端通信。客户端则使用同一个 Socket 进行连接、通信和关闭。
3. 监听与绑定：服务器必须绑定到一个**特定的端口**，并使用 `listen()` 函数监听来自客户端的连接请求。客户端无需绑定端口，因为它是主动连接的，且操作系统会为其分配临时端口。

## 1.listen参数，backlog意义？

backlog决定**TCP全连接队列**的大小，上限值是内核参数somaxconn大小，accept队列长度取两者最小值。

服务端收到SYN报文会创建半连接对象，存放到内核的半连接队列（哈希表结构），队列满了就无法响应连接请求了。

服务端接收到 ACK 报文后，从「 SYN 队列」取出⼀个半连接对象，然后创建⼀个新的连接对象放入到「 Accept 队列」(全连接队列，链表结构)；

## 2.accept发生在握手的哪一步？

在收到第一次握手的时候accept阻塞并发出第二次握手，第三次握手成功accept完成。

客户端的第一次握手，connect进入阻塞状态，收到第二次握手connect返回。

## 3.没有accept可以建立tcp连接吗？

accpet 系统调用并不参与 TCP 三次握手过程，它只是负责从 TCP 全连接队列取出一个已经建立连接的socket，用户层通过 accpet 系统调用拿到了已经建立连接的 socket，就可以对该 socket 进行读写操作了。

## 4.服务端如果只 bind 了 IP 地址和端口，而没有调用 listen 的话，然后客户端对服务端发起 了 TCP 连接建立，此时那么会发生什么呢？

客户端对服务端发起 SYN 报⽂后，服务端回了 RST 报⽂。

## 5.没有listen可以建立TCP连接吗？

可以，客户端可以TCP自连接，也可以两个客户端同时向对方发出请求建立连接。

在执行 listen 方法时，会创建半连接队列和全连接队列。 三次握手的过程中会在这两个队列中暂存连接信息。 所以形成连接，前提是有地方存放着sock信息，方便握手的时候能根据 IP + 端口等信息找到对应的 socket。

客户端的内核有个全局 hash 表，可以用于存放 sock 连接的信息。

在 TCP 自连接的情况中，客户端在 connect ⽅法时，最后会将自己的连接信息放入到这个全局 hash 表 中，然后将信息发出，消息在经过回环地址重新回到 TCP 传输层的时候，就会根据 IP + 端口信息，再一次从这个全局 hash 中取出信息。于是握手包一来一回，最后成功建立连接。

## 5.Socket阻塞和非阻塞的区别？

默认socket是阻塞模式，调用send和recv的时候会等待数据准备好(拷贝到数据缓存区)。非阻塞模式的send和recv会立即返回，操作没完成就返回错误。

# QUIC

## 1.可靠传输改进

乱序确认、有序组装。

主要设计了协议的头部字段，有三层头部：Packet Header、QUIC Frame Header、HTTP3 Frame Header

1. Packet Header 首次建立连接时和日常传输数据时使用的Header是不同的。

   Long Packet Header 用于首次建立连接，包含源连接ID和目标连接ID；Short Packet Header 用于日常传输数据，包含目标连接ID、包编号(Packet Number)、负载数据。

2. Packet Number：(乱序确认：流内队头阻塞)

   **包编号**是独一无二的，严格递增的,一个包丢了，编号就变了。（乱序传输）

   **优点：**①QUIC 支持乱序确认，当数据包Packet N 丢失后，只要有新的已接收数据包确认，当前窗口就会继续向右滑动。②可以更加精确计算 RTT，没有 TCP 重传的歧义性问题。

3. QUIC Frame Header(有序组装)

   一个包有多个QUIC Frame(每个Frame有类型，比如说stream类型，一个stream就是一个HTTP请求)，里面有stream id和offset(类似于 TCP 协议中的 Seq 序号，保证数据的顺序性和可靠性) 通过 Stream ID + Offset 字段信息实现数据的有序性，即使包编号不同，也能根据这两个数据判断出来是不是相同数据。

QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装，摆脱了TCP 必须按顺序确认应答 ACK 的限制，**解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。**

## 2.解决TCP的队头阻塞问题

TCP的重传和按序机制会导致队头阻塞。

在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制自己的滑动窗口。

## 3.流量控制

stream级别：每个stream都有自己的滑动窗口。 接收窗口  = 最大窗口数 - 接收到的最大偏移数。

connect级别：限制连接中所有 Stream 相加起来的总字节数，防⽌发送方超过连接的缓冲容量。

## 4.拥塞控制的改进

默认使用了 TCP 的 Cubic 拥塞控制算法（我们熟知的慢开始、拥塞避免、快重传、快恢复 策略），同时也⽀持 CubicBytes、Reno、RenoBytes、BBR、PCC 等拥塞控制算法，相当于将 TCP 的拥 塞控制算法照搬过来了。 QUIC 处于应用层，所以就可以针对不同的应用 设置 不同的拥塞控制算法，这样灵活性很高。

## 5.更快的连接建立和迁移连接

QUIC 也是需要三次握手来建立连接的，主要目的是为了协商连接 ID。协商出连接 ID 后，后续传输时，双方只需要固定住连接 ID，从而实现连接迁移功能。

TCP 和 TLS 是分层的(分别属于内核实现的传输层、openssl 库实现的表 示层，因此它们难以合并在⼀起，)，需要分批次来握手，先 TCP 握手（1RTT），再 TLS 握手（2RTT），一共3RTT。QUIC支持TLS1.3，在1个RTT中同时完成连接建立与密钥协商。客户端可以使用先前会话的信息来快速恢复会话(0-RTT)。

①客户端在发送 QUIC 的初始连接请求时（即 QUIC 的第一个数据包），直接嵌入了 **TLS 1.3 的 ClientHello 消息**（TLS第一次握手）。这意味着客户端在发送连接请求的同时，也发出了进行密钥协商的必要信息。②服务端在收到客户端的初始 QUIC 数据包后，立即返回 **ServerHello** 消息，同时包含 QUIC 的连接信息和 TLS 1.3 的加密协商信息。③完成finish消息验证：用对称密钥加密数据，确认密钥交换完成。

迁移连接：QUIC 协议通过 **连接 ID** 标记通信双方，而不依赖传统的四元组（IP 地址和端口）。因此，即使移动设备的网络发生变化，导致 IP 地址改变，只要连接 ID 和 TLS 密钥等上下文信息保持不变，设备就能继续使用原连接，实现无缝迁移，避免重连的开销，消除卡顿感。

# HTTP断点续传

**HTTP 中的断点续传**是一种允许在文件传输过程中因网络中断或其他原因导致传输失败后，重新连接并从上次中断的地方继续传输的技术。它通常用于下载大文件，使得在网络不稳定或传输意外中断时，不必重新开始下载整个文件，而是从中断的地方继续下载。这种机制可以大大提高用户体验和网络资源利用效率。

### 断点续传的原理

在 HTTP 中，断点续传主要依赖于**HTTP 请求头中的 `Range` 字段**来实现。`Range` 字段允许客户端指定想要请求的文件的字节范围。服务器收到请求后，可以返回指定范围的数据，而不是整个文件。

具体过程如下：

1. **客户端请求部分内容**：当客户端想要从某个位置继续下载时，发送一个带有 `Range` 请求头的 HTTP 请求。
   - 例如，`Range: bytes=500-` 表示请求从第 500 字节开始的内容直到文件末尾。
   
2. **服务器返回部分内容**：如果服务器支持断点续传（支持 `Range` 请求），会返回状态码 `206 Partial Content`，并在响应头中包含 `Content-Range` 字段，表示返回的是部分内容。
   - 例如，`Content-Range: bytes 500-999/1000` 表示返回的内容是文件的 500-999 字节，共 1000 字节。
   
3. **客户端接收并继续下载**：客户端接收服务器返回的部分内容，并将其追加到之前下载的部分内容之后，直到文件下载完成。

### 实现断点续传的步骤

1. **客户端发起断点续传请求**：
   - 在第一次下载时，记录已下载的字节数（如使用 `Content-Length` 来获取文件总长度）。
   - 如果下载中断，重新连接时可以通过发送带 `Range` 请求头的 HTTP 请求，从上次中断的地方继续下载。
   
   ```http
   GET /path/to/file HTTP/1.1
   Host: example.com
   Range: bytes=500-  # 从第500字节继续请求
   ```

2. **服务器响应部分内容**：
   - 如果服务器支持断点续传功能，它会解析 `Range` 请求头，并返回指定范围的数据，同时带上 `206 Partial Content` 状态码和 `Content-Range` 响应头。
   
   ```http
   HTTP/1.1 206 Partial Content
   Content-Range: bytes 500-999/1000
   Content-Length: 500
   ```

3. **客户端拼接数据**：
   
   - 客户端收到部分内容后，将新下载的数据与之前已下载的数据拼接，直到文件全部下载完成。

### 服务器支持断点续传的要求

并不是所有服务器都支持断点续传，服务器需要满足以下条件：
- **支持 `Range` 请求头**：服务器需要实现对 `Range` 请求的解析，以返回部分内容。
- **返回 `206 Partial Content` 响应**：当接收到 `Range` 请求时，服务器需要返回 `206` 状态码来表示部分内容响应。
- **支持 `Content-Range` 响应头**：服务器需要在响应头中包含 `Content-Range` 字段，告知客户端返回的是文件的哪个字节范围。

大部分现代 Web 服务器（如 Nginx、Apache）都支持断点续传，通常默认启用 `Range` 请求处理。

### 示例代码（使用 `curl` 测试断点续传）

可以使用 `curl` 命令测试服务器是否支持断点续传：

```bash
# 下载前500字节
curl -o part1 -r 0-499 http://example.com/path/to/file

# 从500字节开始继续下载
curl -o part2 -r 500- http://example.com/path/to/file

# 将两部分拼接
cat part1 part2 > complete_file
```

### 常见应用场景

- **大文件下载**：如视频文件、软件安装包等，防止因网络中断导致需要重新下载整个文件。
- **下载管理器**：许多下载工具（如 IDM、迅雷）利用断点续传来加速下载，甚至可以分段多线程下载文件的不同部分。
- **浏览器下载**：现代浏览器支持断点续传，用户在下载过程中暂停并重新继续下载。

### 总结

- **断点续传** 是一种允许从中断处继续下载的机制，主要依赖 HTTP 协议中的 `Range` 和 `Content-Range` 头。
- **实现方式**：客户端发送带 `Range` 的请求，服务器返回 `206 Partial Content` 响应及 `Content-Range` 头。
- **应用场景**：用于大文件下载、下载管理器等，提升下载体验和效率。