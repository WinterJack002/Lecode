![image-20241023104715659](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410231047472.png)

# 一、进程线程

## 1.进程、线程、协程的区别和联系

1. 定义
   1. 进程：资源分配和拥有的基本单位，每个进程拥有独立的内存空间。
   2. 线程：程序执行的基本单位，线程是在进程内部执行的。一个进程可以包含多个线程。
   3. 协程：用户态的轻量级线程，属于线程内部调度的基本单位。协程在同一个线程内运行，多个协程共享同一线程的执行上下文。
2. 拥有资源。
   1. 进程：拥有独立的内存空间、CPU资源、文件资源和句柄等。
   2. 线程：共享进程的内存空间，但拥有独立的寄存器、栈和线程控制块。
   3. 协程：拥有自己的寄存器上下文和栈，多个协程共享同一线程的资源和上下文。
3. 切换的系统开销。
   1. 进程：涉及完整的CPU上下文切换，包括寄存器、堆栈、页表和文件句柄等资源的保存与恢复。进程切换需要进入内核态，开销较大。
   2. 线程：线程切换需要保存和设置程序计数器、少量寄存器的内容，切换速度快于进程，但仍需进入内核态。
   3. 协程：协程切换发生在用户态，通过保存和恢复寄存器和栈的内容来实现，不涉及内核态切换，因此切换速度非常快。
4. 调度者
   1. 进程和线程：由操作系统调度，系统内核决定进程的执行顺序和时间片分配。
   2. 协程：由用户级代码调度，用户代码决定协程的执行顺序和切换时机，协程切换完全在用户态进行。
5. 进程是资源分配的基本单位，线程是资源调度的基本单位。

## 1.1进程有哪些资源？哪些资源是线程共享的？

资源：CPU时间、内存、文件描述符(指向内核中打开文件的表项)、PCB、IO设备(键盘)、网络连接、权限管理、信号量。

CPU时间栈是不能共享的，线程有自己的TCB，有自己的寄存器、栈。

## 1.3进程和线程的上下文切换分别切换什么？

### 1. **进程切换**

进程是具有独立资源的执行单元，每个进程有自己独立的内存空间和系统资源。**进程切换**是指从一个进程的执行切换到另一个进程的执行，这种切换开销较大，需要切换的资源包括：

- **CPU 寄存器**：进程的上下文，包括程序计数器（PC）、栈指针（SP）、通用寄存器等，这些需要保存和恢复，以便进程能够从正确的状态继续执行。
- **内存管理信息**：进程的地址空间，内存页表和段表需要切换，以确保 CPU 能够访问到正确的内存区域。
- **文件描述符表**：每个进程都有自己独立的文件描述符表，切换时需要处理与进程相关的文件句柄。
- **进程控制块（PCB）**：进程的状态信息保存在 PCB 中，包括进程的标识符、优先级、状态、打开的文件列表、信号处理信息等。切换时，旧进程的 PCB 会被保存，新进程的 PCB 会被加载。
- **虚拟内存页表**：操作系统需要切换页表以对应新的进程的地址空间。

### 2. **线程切换**

线程是进程的执行单元，多个线程共享同一个进程的资源（如内存、文件等）。**线程切换**通常发生在同一进程内，因此相比进程切换，开销较小。线程切换涉及的资源包括：

- **CPU 寄存器**：线程上下文包括程序计数器、栈指针等，类似于进程切换，但不涉及内存页表的切换。
- **栈（Stack）**：每个线程有自己的栈，用于存储局部变量、函数调用信息等。线程切换时，需要保存当前线程的栈指针，并恢复新线程的栈指针。
- **线程控制块（TCB, Thread Control Block）**：每个线程有自己的 TCB，保存线程的状态、寄存器信息、栈地址等。切换时需要保存和恢复这些信息。

由于线程共享进程的内存空间和资源，线程切换时**无需切换内存页表和文件描述符表**，因此线程切换的开销小于进程切换。

## 2.进程调度算法

1. 调度原则

   1. CPU利用率。
   2. 系统吞吐量。吞吐量：单位时间内CPU完成进程的数量。长作业降低吞吐量，短作业提升吞吐量。
   3. 周转时间。进程运行、等待和阻塞时间总和，越小越好。
   4. 等待时间。进程处于就绪队列的时间。越小越好。
   5. 响应时间。第一次提交到响应花费的时间。

2. 单核CPU系统常见的调度算法

   1. **先来先服务(FCFS)** 非抢占式调度算法，按照请求顺序进行调度，利好长作业。

   2. **最短作业优先调度算法(SJF)** 非抢占式调度算法，优先选择运行时间最短的进行运行，有助于提高系统的吞吐量。

   3. **高响应比优先调度算法(HRRN)** 调度前先计算响应比优先级，(等待时间 + 要求服务时间) / 要求服务时间。响应比优先级高的先运行。权衡了短作业和长作业。

   4. **时间片轮转(RR)** 每个进程分配一个时间片，时间片用完就换下一个进程。时间片一般为20-50ms。

   5. **最高优先级调度算法(HPF)** 为进程分配优先级，按照优先级进行调度。

      1. 静态优先级。创建的时候就确定。
      2. 动态优先级。随时间的推移增加等待进程的优先级。

      3. 非抢占式：就绪队列出现优先级高的进程，运行完当前进程，再选择优先级高的。
      4. 抢占式：就绪队列出现优先级高的进程，当前进程挂起，放入就绪队列，先执行优先级高的进程。

   6. **多级反馈队列调度算法**。时间片轮转和最高优先级算法的综合。
      1. 多级表示有多个队列，优先级越高的队列，时间片越短。
      2. 新进程会加入到第一级队列中，按照先来先服务排队，如果在一级队列没完成，则加入到第二级队列的末尾，以此类推。
      3. 高优先级队列为空才调度低优先级的队列中的进程运行。进程运行中，有新进程加入，则停止当前进程并将其移入到原队列末尾，让高优先级的先运行。
   
3. Linux默认的调度算法

   完全公平调度器(CFS)：在理想的环境中，CPU 时间应该按比例公平分配给所有进程。
   
   为了公平分配 CPU 时间，它通过虚拟运行时间来跟踪每个进程的使用时间，确保进程能够获得合理的 CPU 资源。
   
   每个进程都有一个 **vruntime** 值，表示该进程的 **加权运行时间**。运行时间越长，`vruntime` 的值越大。权重（由进程的优先级决定）越高的进程，其 `vruntime` 增加得越慢，低优先级进程的 `vruntime` 增加得更快。这样，CFS 可以保证优先级高的进程比优先级低的进程获得更多的 CPU 时间。
   
   CFS 使用 **红黑树** 来管理所有待调度的进程。每个进程根据其 `vruntime` 值插入到红黑树中，树中的最左节点（即 `vruntime` 最小的进程）是下一个将被调度的进程。通过这种机制，CFS 可以高效地找到 `vruntime` 最小的进程，并将其调度到 CPU 上。
   
   CFS 使用一种称为 **调度间隔（Scheduling Period）** 的机制，将 CPU 时间划分为多个调度周期。在每个调度周期内，系统尝试让所有进程都至少执行一次。进程的运行时间与其权重成正比。

## 3.进程通信(借助内核空间来实现进程间通信)

1. **管道**。半双工，数据只能单向流动。**无格式的字节流数据**。数据缓存在内核，不支持文件定位。
   1. 匿名管道：借助**内存文件**，只能在父子进程之间或兄弟进程之间使用。
   2. 命名管道：借助**文件系统**，允许非父子进程使用，先进先出。
   
   优点：简单易用 缺点：字节流传输，无法进行定位。
   
   **使用场景**：父子进程间的简单通信。命名管道:简单通信的场景.
   
2. **消息队列**。消息队列是保存在内核中的**消息链表**，每个**消息体**都是固定大小的存储块。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。
   1. 优点：消息是**有结构化**的，可以按照优先级处理消息。
   2. 缺点：通信速度不及时。附件有大小限制。
      1. 不适合比较大数据的传输，
      2. **存在用户态与内核态之间的数据拷贝开销。**
      3. 消息过多时可能会阻塞或导致数据丢失。

   **使用场景**：在服务器和多个客户端之间传递简短消息。

3. **共享内存**。

   1. 映射一段能被其他进程访问的内存，这段内存可被多个进程访问。不需要拷贝，加快了通信速度。

   2. 分为匿名共享内存和命名共享内存。

      1. 匿名共享内存无法通过名字访问，适合父子进程共享数据，使用mmap创建。使用MAP_SHARED标志可以确保不发生写时复制。（父子进程在fork之后共享相同的物理内存，写时复制会确保改动的时候分配新的物理内存）。

      2. 命名共享

         POSIX 提供了 `shm_open()` 函数，用于创建或打开一个**共享内存对象**。共享内存对象会由一个命名标识符（通常是一个字符串名称）来表示。使用 `mmap()` 将**共享内存对象**映射到当前进程的虚拟内存中。

         第一个进程创建共享内存对象，后续的进程打开，映射同样的共享内存对象时，操作系统将更新进程 2 的页表条目，使其虚拟地址指向**相同的物理内存页**。

      ```CPP
      int shm_fd = shm_open("/my_shared_memory", O_CREAT | O_RDWR, 0666);
      ftruncate(shm_fd, SIZE);  // 设置共享内存的大小
      void *ptr = mmap(0, SIZE, PROT_READ | PROT_WRITE, MAP_SHARED, shm_fd, 0);
      ```

   3. 优点：

      **高效**：没有数据拷贝，直接在内存中共享数据，速度非常快。

      **灵活**：可以存储复杂的数据结构，如数组、链表等。

   4. 缺点：

      需要使用同步机制（如信号量、互斥锁）来防止**并发访问问题**（如竞争条件、数据一致性问题）。

      共享内存不适合小数据量的频繁传递，因为需要额外的同步开销。

      实现起来相对复杂，特别是处理同步问题。

   **使用场景**：①适用于需要**高效、频繁、大量数据传输**的场景，如多进程数据库系统、多媒体处理系统等。②常用于**视频处理**或**图像处理**中，多个进程对同一块数据进行高效处理。

4. **信号量。**进程使用System V信号量，信号量是计数器，表示资源个数。防止多进程竞争共享资源而造成的错乱。实现进程间的互斥与同步。P操作-1，V操作+1，成对出现。

   1. 初始化信号量为1代表着互斥信号量，保证了共享内存只有一个进程访问。
   2. 初始化信号量为0可以实现多进程同步。可以保证进程的顺序执行。

   优点：提供进程间同步功能，可以避免竞争条件、死锁等并发问题。能和共享内存配合使用。

   缺点：**不传递数据**，只是用于同步和控制访问。

   **使用场景**：通常与**共享内存**结合使用，用于进程间同步和资源控制。适用于**生产者-消费者问题**、**读者-写者问题**等需要进程同步的场景。

5. **信号。**异常情况下的工作模式，用信号通知进程。(**唯一的异步通信机制**)。信号来源：Cltr+C，Kill命令。
   1. 信号可以执行默认操作
   2. 捕捉信号执行相应的信号处理函数(处理函数可以注册)
   3. 忽略信号，不做处理。sigkill、sigstop是无法忽略的，用于结束、暂停(挂起)某一进程。

   优点：传递机制简单、快速，适合异步；缺点：信号的**信息量有限**

   **使用场景**：常用于**进程控制**，如进程的终止、暂停、重启等。

6. **套接字。**跨网络与不同主机上的进程之间通信(TCP,UDP)，也可以在同主机上进程间通信。

   1. TCP字节流，UDP数据包。
   2. 本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端⼝，⽽是**绑定一个本地文件**，这也就是它们之间的最⼤区别。

   优点：支持**本地进程和网络进程**的通信。支持双向，通信灵活。

   缺点：相对于共享内存等方式，套接字的**通信效率较低**，尤其是在传输大量数据时，开销较大。

   **使用场景**：适合网络通信场景，如**客户端-服务器**架构、**分布式系统**等。

## 4.守护进程、僵尸进程和孤儿进程

### 僵尸进程

1. 产生原因
   1. 子进程先于父进程终止,而父进程没有及时调用 `wait()` 或 `waitpid()` 函数来获取子进程的终止状态。
   2. 父进程退出时,没有正确地处理子进程,导致子进程成为僵尸进程。
2. 特点

   进程已经不再占用任何系统资源，但PCB仍然保留在操作系统的进程表中。僵尸进程只占用很少的内核数据结构,不会对系统的正常运行造成太大影响。但是,如果系统中存在大量的僵尸进程,会消耗系统的进程表资源,影响新进程的创建。
3. 怎么避免？
   1. 在父进程中调用 `waitpid()` 或 `wait()` 函数等待子进程终止。
   2. 当子进程终止时，父进程会收到 `SIGCHLD` 信号。可以在父进程中捕捉并处理该信号，以调用 `wait()` 或 `waitpid()` 以非阻塞方式回收子进程资源。
   3. 忽略SIGCHLD信号，使内核可以自动回收已终止的子进程的资源。
   4. fork两次，父进程fork一个子进程，然后继续工作，子进程fork一个孙进程后退出，孙进程变成了孤儿进程，由init进程接管。

### 守护进程(双fork的使用)

在后台运行的，没有控制终端与之相连的进程。独立于控制终端，周期性的执行某种任务。

1. 脱离控制终端
   1. 调用fork创建子进程，主进程exit退出。
   2. 子进程中调用setsid创建新会话，成为会话领导者。
   3. fork出孙进程 当子进程成为会话首进程后,它仍然可能会意外地重新获得控制终端。子进程exit退出
   4. 切换工作目录到根目录。
2. 重定向标准输入输出错误，使用close关闭掉文件描述符0-2。
3. umask(0)重设文件权限掩码，获得完全权限。
4. 信号处理:将SIGCHLD忽略掉。SIGCHLD：子进程终止或停止时发送给父进程的信号。

### 孤儿进程

孤儿进程是父进程已经终止、但它本身还没有结束的进程。孤儿进程不会对系统性能造成负面影响，因为操作系统（如Linux的init进程(进程号为1)）会自动接管这些进程并在适当的时候进行清理。操作系统的init进程会周期性地调用wait()来回收任何已终止子进程的资源，防止它们变成僵尸进程。

## 5.进程的状态及其切换？

![image-20240718104541715](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010647.png)

## 6.进程控制块 (PCB) 的作用是什么？

1. 唯一标识进程：通过进程标识符 (PID) 唯一标识每个进程。
2. 存储进程状态：**记录进程的当前状态**，如运行、就绪、等待等。
3. 保存寄存器上下文：保存进程的CPU寄存器值，如程序计数器、栈指针等，用于上下文切换。
4. 管理内存分配：**跟踪进程的内存使用情况**，包括代码段、数据段、堆、栈等。
5. 文件描述符表：记录进程打开的文件及其对应的文件描述符。
6. 进程调度信息：包含进程的优先级、时间片等调度相关信息。
7. 进程间通信：**管理进程间通信的相关信息**，如管道、消息队列、共享内存等。

## 7.线程的通信方式？

1. 共享内存。线程之间共享程序的公共状态，线程之间通过读-写内存中的公共状态来隐式通信。
2. 消息队列和管道：线程之间没有公共的状态，线程之间必须通过明确的发送信息来显示的进行通信。
3. 条件变量：条件变量是一种同步原语，用于实现线程之间同步。
4. 信号量：信号量是一种用于实现线程间通信的同步原语。它允许多个线程之间共享一个计数器，当计数器的值大于0时，线程可以继续执行；当计数器的值为0时，线程将被阻塞，直到其他线程释放资源。

## 8.怎么回收线程，有哪几种方法？

1. pthread_join()：主线程调用，等待子线程退出并回收其资源，类似于进程中wait，调用pthread_join()的线程会被阻塞。
2. pthread_detach()：调用后和主线程分离，子线程结束时自己立即回收资源。
3. pthread_exit()：子线程执行，用来结束当前线程，并通过retval传递返回值，返回值可以通过pthread_join获得。

使用 `join`：当需要等待线程完成，确保资源管理和顺序执行时。

使用 `detach`：当希望线程在后台独立执行，且不需要与主线程交互时。

## 8.线程同步的方式？

数据竞争：多线程在没有同步机制的情况下同时操作同一个数据资源。

数据同步是指在多线程环境中，通过各种机制确保**对共享数据的访问以一种可控和一致的方式进行。**

1. 锁：互斥锁、自旋锁、读写锁
2. 条件变量：通过条件变量来实现线程之间的等待和唤醒。当线程需要等待某个条件满足时，可以调用条件变量的等待函数使自己进入等待状态；当条件满足时，可以调用条件变量的唤醒函数唤醒等待的线程。
3. 信号量：作为一种计数器，用于控制对共享资源的访问，限制并发访问的线程数。
4. 原子操作：不可分割的操作单元，确保在读取、修改和更新值的过程中不会被其他线程中断。用于实现无锁的数据结构。

## 9.锁(互斥)

1. **自旋锁(忙等待锁)**

   在用户态完成加锁和解锁操作，不会主动产生线程上下文切换。**加锁失败的线程会忙等待，直到拿到锁。**

   单核CPU需要抢占式的调度器，否则自旋锁在单CPU上无法使用，因为自旋的线程不会放弃CPU。

2. **互斥锁(无忙等待锁)**

   互斥锁加锁失败，会从用户态陷入内核态，内核来切换线程。成本是两次线程上下文切换；耗时在几十纳秒到几微秒，锁的代码执行时间很短，就不用互斥锁，而是用自旋锁。

   **加锁失败时，互斥锁用线程切换来应对，自旋锁用忙等待来应对。**

3. **读写锁**

   **写锁是独占锁，读锁是共享锁。**

   使用场景：用于 “多读少写” 的场景，读写锁支持多个读操作并发执行，写操作只能由一个线程来操作。**能明确区分读操作和写操作的场景**

   1. 写锁空闲，多个线程可以并发地持有读锁。
   2. 写锁被持有，获取读锁和写锁的操作被阻塞。

   分类

   1. **读优先锁**(可能造成饥饿)	
      1. 优先保证读锁，有写锁在等待还能获得读锁。**读锁全部释放才能获得写锁。**
   2. **写优先锁**(可能造成饥饿)
      1. 优先保证写锁，有写锁在等待就不能获得读锁了。
   3. **公平读写锁**，用队列把获取锁的线程排队，先进先出原则加锁。

4. **乐观锁和悲观锁**

   1. 悲观锁：互斥锁、自旋锁、读写锁。访问共享资源之前要先上锁。
   2. 乐观锁：**假定冲突概率很低**，先修改共享资源，再验证是否在这段时间发生了冲突，如果没有发生冲突，那么操作完成，如果冲突就放弃本次操作。(无锁编程)
      1. 在线文档。用户提交修改时，发给服务端的请求会带上原始文档版本号，版本号一致则修改成功。

## 9.1无锁编程

1. 原子操作

   现代 CPU 提供了多种原子操作指令，如 **Compare-and-Swap (CAS)**、**Test-and-Set**、**Fetch-and-Add** 等。这些指令能够保证多个线程或进程并发访问相同的内存位置时，不会产生竞争条件。CPP中的**atomic接口**利用底层的硬件指令或其他同步机制来确保操作的原子性。

   ```cpp
   atomic提供了多种操作，包括但不限于：
   - load()：安全地读取原子对象的值。
   - store()：安全地写入原子对象的值。
   - exchange()：原子地替换原子对象的值。
   ```

   原子操作是无锁编程的基础。

无锁队列：无锁队列是一种基于链表实现的队列数据结构，它也使用原子操作来确保线程安全。无锁队列的实现通常使用两个指针，一个指向队头元素，另一个指向队尾元素。入队和出队操作都是通过原子操作来修改这两个指针，从而实现线程安全。

2. 内存一致性

   即使操作本身是原子的，但如果内存的写入和读取顺序没有得到保证，仍然可能导致数据不一致或不可预见的行为。因此，需要通过 **内存屏障**（Memory Barriers）或 C++11 提供的 `memory_order` 来显式控制内存的顺序。

   **内存顺序一致性**决定了在多线程环境中，某个线程对共享变量的修改何时对其他线程可见。现代 CPU 和编译器为了提高性能，可能会对指令进行重排序，这会影响多线程之间的操作顺序和可见性。因此，在无锁编程中，控制内存操作的顺序非常重要，以确保程序在不同平台上表现一致。

**C++的六种内存序**

内存序是C++并发编程中的知识点，它可以控制多线程程序中变量之间的访问顺序。C++11标准引入了六种内存序，程序员可以针对不同的场景选择合适的内存操作语义。这六种内存序分别是

   1. memory_order_relaxed:这是最弱的内存序，不保证任何跨线程的同步，仅保证原子操作的原子性，不保证同步的顺序(因为可能涉及到指令重排序)。适用于无需跨线程的同步场景。
   2. memory_order_consume:比 memory_order_relaxed 稍强，但仅在数据依赖的场景下有序(已经在很多编译器中被 memry_order_acquire 代替)。
   3. **memory_order_acquire** :读取操作在此之前的所有操作在它之前执行。适用于获取锁或同步操作需要确保先前的操作完成.
   4. **memory order release** :写入操作在此之后的所有操作在它之后执行。常用于解锁操作，确保之前的操作都完成后才释放锁。
   5. memory_order_acq_rel:结合 memory_order_acquire 和 memory_order_release 的语义，用于读-改-写操作，确保读取之前的操作在它之前完成，写入之后的操作在它之后进行。
   6. memory_order_seq_cst:这是最强的内存序，保证所有线程的操作按严格的全局顺序进行。适用于需要严格顺序的场景，通常是默认选择。


**内存屏障**：**内存屏障的作用**就是通过插入特殊指令，防止 CPU 或编译器对特定的内存操作进行重排序，**确保在执行这些关键操作时，内存访问的顺序和结果符合预期。**

   1. **加载屏障（Load Barrier）类似于memory_order_acquire **：
   
      当前线程在读取这个共享变量时，其他线程通过 `memory_order_release` 进行的所有写入已经可见。
   
      所有在 `memory_order_acquire` 之后的读/写操作不会被重排序到这个读取操作之前。
   
   2. **存储屏障（Store Barrier）类似于memory_order_release**：
   
      确保在执行某个写操作（store 操作）时，当前线程在这之前的所有**读/写操作**都已经完成，并且保证这些操作对其他线程是可见的。
   
      用于**写入共享变量**时，确保在当前线程修改变量时，之前的所有读写操作都已提交，后续的操作不会在当前操作之前被执行。

## 10.死锁

死锁问题的产生是由两个或者以上线程并行执行的时候，争夺资源而互相等待造成的。

1. 死锁的条件

   1. **互斥条件**：多个线程不能使用同一个资源。
   2. **不可剥夺条件**：在线程使用完资源前，不能被抢走。
   3. **持有并等待条件**：线程当前所拥有的资源在请求其他新资源时，由该线程继续占有。
   4. **环路等待条件**：两个线程获取资源的顺序构成了环形链。

2. 避免死锁

   使用资源有序分配法，来破坏环路等待条件。

   有序分配法：线程以相同的顺序获取自己想要的资源

3. 处理方法

   1. 鸵鸟策略：Unix、Linux和windows，处理死锁仅仅是忽略它。
   
4. 银行家算法

   银行家算法是一种用于避免死锁的资源分配算法，其核心思想是在分配资源前，首先判断系统是否安全。如果系统安全，才进行资源分配。

   银行家算法通过一系列数据结构描述系统状态，包括：

   - **Available**: 系统当前可用资源
   - **Max[i]**: 进程 i 最大需求量
   - **Allocation[i]**: 进程 i 已分配的资源
   - **Need[i]**: 进程 i 还需要的资源
   - **Request[i]**: 进程 i 当前的资源请求

   在判断系统安全性时，会用**安全性算法**计算 `Work` 和 `Finish` 等数据结构来确定是否满足所有进程的需求。若满足，则系统安全，资源可以分配；否则，系统不安全，不能进行分配。

   当有请求时，会先判断是否小于等于自身的需求和可用资源，若满足就试探性分配，再用**安全性算法**判断状态是否安全以决定是否真正分配资源。

5. 检测死锁

   Helgrind 是 Valgrind 的一个工具，用于检测多线程程序中的数据竞争和死锁问题。它可以帮助检测到可能的死锁条件。

```cpp
#include <iostream>
#include <thread>
#include <mutex>
#include <chrono>
using namespace std;
mutex mutex1;
mutex mutex2;
void thread1() {
    lock_guard<mutex> lock1(mutex1);
    // 模拟一些工作
    this_thread::sleep_for(chrono::milliseconds(100));  
    lock_guard<mutex> lock2(mutex2);
    cout << "Thread 1 finished\n";
}
void thread2() {
    lock_guard<mutex> lock2(mutex2);
    // 模拟一些工作
    this_thread::sleep_for(chrono::milliseconds(100));  
    lock_guard<mutex> lock1(mutex1);
    cout << "Thread 2 finished\n";
}
int main() {
    thread t1(thread1);
    thread t2(thread2);
    t1.join();
    t2.join();
    return 0;
}
```

## 11.条件变量的缺点及为何需要与互斥锁（mutex）配合使用？

1. **缺点**:
   - **不能单独使用**: 条件变量**本身无法保证线程安全**,必须与互斥锁配合使用才能正确工作。
   - **容易产生死锁**: 如果使用不当,可能会导致死锁的发生。比如,一个线程在持有锁的情况下调用 `wait()` 而无法释放锁,其他线程无法获取锁从而无法唤醒等待线程。
   - **易产生虚假唤醒**: 线程可能无故被唤醒。这**要求线程在被唤醒后还需要重新检查条件。**
2. **需要与互斥锁配合使用的原因**:
   - **保证线程安全**: 条件变量需要与互斥锁配合使用,才能确保线程对共享资源的访问是互斥的,从而保证线程安全。
   - **避免死锁**: 使用条件变量时,必须先获取互斥锁,然后再调用 `wait()` 释放锁进入等待状态。这样可以避免死锁的发生。
   - **避免虚假唤醒**: 当线程被条件变量唤醒时，它会首先重新获取互斥锁，然后才能继续执行。这确保了在检查条件的过程中，没有其他线程可以修改共享资源。因此，即使发生了虚假唤醒，线程在重新检查条件时，依然能够在受保护的环境下正确判断条件是否满足。

## 12.中断和异常有什么区别？

**中断**

1. 硬中断:是由外部硬件设备（如键盘、鼠标、网络卡、定时器等）触发的中断信号，**目的是通知CPU有外部事件需要处理。**会中断现有任务。
2. 软中断:用于处理系统调用、操作系统调度、网络协议栈处理等，用于**延迟处理一些不紧急但需要优先执行的任务。**

软中断通常在硬中断处理完后执行，作为一种延迟处理机制。

**异常**是由CPU执行指令的内部事件引起，如:非法操作码、地址越界等。

## 13.并发和并行的区别？

1. 并发(IO密集)
   1. 多个任务交替执行，给人同时进行的错觉
   2. 任务切换提高响应性和资源利用率
   3. 可以在单核处理器上实现
2. 并行(计算密集)
   1. 多个任务在同一时刻同时进行
   2. 需要多核处理器或多个处理器。
   3. 提高计算速度和处理能力
   4. 任务之间是真正的同时执行。

## 14.用户级线程和内核级线程的区别？

### 1.用户级线程（User-Level Threads, ULT）

1. 线程管理：用户级线程的创建、管理和销毁都在用户空间进行，不需要内核的参与。这些线程通常由线程库（如POSIX线程库）管理。
2. 上下文切换：由于上下文切换在用户空间完成，不涉及内核态的切换，因此速度快，开销小。
3. 系统调用：用户级线程的操作无需系统调用，这使得线程操作更加高效，但在进行I/O操作时，整个进程会被阻塞。
4. 多线程调度：用户级线程由用户级库调度，无法利用多核处理器的优势，因为内核只看到单个进程，而不识别其内部的多个线程。

### 2.内核级线程（Kernel-Level Threads, KLT）

1. 线程管理：内核级线程的创建、管理和销毁由操作系统内核负责，需要通过系统调用进行。
2. 上下文切换：上下文切换需要从用户态切换到内核态，这使得切换速度较慢，开销较大。
3. 系统调用：内核级线程的操作需要系统调用，尽管开销较大，但可以利用操作系统的各种功能，如进程调度和I/O操作。
4. 多线程调度：内核级线程由操作系统调度，可以充分利用多核处理器的优势，因为内核能够识别和管理每个线程。

## 15.Linux常用命令你知道哪些？

```shell
1. 文件相关：
	mv：mv source_file destination mv old_name new_name
    mkdir mkdir new_directory
    cd ls -l 详细显示显示文件权限、所有者、大小、最后修改时间等信息。
    ln： ln srcfile linkname 软连接：ln -s srcfile linkname
    cat 显示文件内容 
2. 进程相关：
	ps ：显示当前系统中的 进程信息 
	ps aux：列出系统中所有用户的进程，包括运行时长、CPU 使用率等信息。
	top(实时进程监控) ：实时监控系统中的进程和系统资源使用情况。它会不断刷新显示 CPU、内存等资源的使用情况，便于监控系统性能。
	kill： kill -9 pid kill 立即终止进程
3. 权限相关：
	chmod ：用于修改文件或目录的权限。权限分为三类：所有者（Owner）、所属组（Group） 和 其他人（Others）。权限分为读、写、执行。 3 个八进制数值来表示权限，分别对应所有者、组用户和其他用户
	# 所有者有读、写、执行权限，组用户和其他人有读、执行权限
	chmod 755 file  
	chown：用于改变文件或目录的 所有者 和/或 所属组。
	useradd：用于在系统中 创建一个新用户。
    groupadd：用于在系统中 创建一个新组。
4. 网络相关：
    netstat：显示网络连接、路由表、接口状态、网络协议统计等信息。
    ip addr：显示所有网络接口的 IP 地址和相关信息。
5. 测试相关：网络联通性：ping 端口联通性：telnet
6. 查看磁盘剩余空间
    df -h 磁盘总大小、已使用的空间、剩余空间、已使用百分比、挂载点
    du -h /path/to/directory 查看特定目录或文件占用的磁盘空间
```

## 16.什么时候该用多线程，什么时候该用多进程？

多线程使用：

1. **共享内存和资源**：当需要多个执行单元共享大量数据或状态时，线程是更好的选择。

2. **轻量级并发任务**：线程的创建和销毁比进程更快，资源开销较小。如果应用程序需要**频繁地创建和销毁执行单元**，或者需要大量轻量级的并发操作，线程通常是更合适的选择。


多进程使用：

1. **隔离和安全性：**进程提供了更好的隔离级别，**每个进程拥有自己的内存空间和系统资源。**这种隔离可以防止进程间的干扰，并提高系统的稳定性。在安全性和稳定性要求较高的应用中，如网银系统，多进程是更佳的选择。
3. **可靠性稳定性**：使用多进程可以避免一个进程中的错误影响到其他进程，提高**程序的健壮性**。

## 17.什么情况适合用协程池，什么情况适合用线程池?

协程池适合 I/O 密集型、资源利用低(任务时间较短)、并发性要求不高的场景

线程池适合 CPU 密集型、并发性要求高、任务时间较长的场景。

## 18.程序什么时候单线程效率高？

1. **任务不需要并行处理**：任务本质上是顺序的，没有并行执行的需求或潜力，使用单线程可能更简单且高效。
2. **I/O密集型应用**：**在I/O密集型应用**中，程序的性能瓶颈通常是磁盘I/O或网络I/O，而不是CPU。在这种情况下，使用多线程可能不会带来明显的性能提升，因为大部分时间都花在了等待I/O操作完成上。单线程模型在这种情况下简化了设计，且效率足够高。
3. **内存使用优化**：在**内存资源受限的环境中**，单线程程序能更好地利用有限的内存资源。
4. **非共享资源的操作**：如果程序中的任务完全独立，不需要共享任何资源，单线程执行可能更为直接和高效。这样可以避免多线程程序中资源锁定和同步的复杂性。

## 19.可执行文件变成进程的过程

1. 加载可执行文件
   操作系统会解析可执行文件的格式(如 ELF、Mach-O 等),并提取出程序代码、数据以及依赖的共享库等信息。
2. 创建进程控制块 (PCB)
   操作系统为新进程创建一个进程控制块(PCB)，PCB是操作系统用来维护进程状态、程序计数器、CPU寄存器信息、内存管理信息和其他关键信息的数据结构。
3. 分配内存
   操作系统会为这个新的程序分配独立的内存空间,包括代码段、数据段、堆和栈等。
4. 初始化程序运行环境
   操作系统会初始化程序的执行环境,包括设置程序的权限、建立进程上下文、准备好命令行参数和环境变量等。
5. 加载共享库
   如果程序依赖某些共享库,操作系统会自动加载这些库,并将它们映射到进程的地址空间中。
6. 准备执行
   操作系统将**程序计数器(PC)设置到可执行文件指定的入口点**，准备执行程序的第一条指令。

7. 调度和执行
   操作系统的调度器将进程加入到调度队列，根据调度策略（如轮询、优先级调度等），进程将被CPU执行。

## 20.CPU缓存如何影响计算性能？解释缓存的概念。

缓存（Cache）是一种**临时存储数据的高效存储器**，位于CPU和主存之间，用于存储经常访问的数据。缓存的主要目的是**加速数据访问速度**，减少从主存获取数据的延迟，提高CPU的处理性能。基于时间局部性。

1. **加速数据访问：**

   **原理：**缓存存储的是CPU经常访问的数据，通过减少访问主存的次数，提高了数据访问速度。

   **效果：**提高了CPU的处理性能，减少了处理等待时间。

2. **减少内存延迟：**

   **原理：**从缓存中获取数据的速度远高于从主存中获取数据的速度。

   **效果：**减少了数据访问的延迟，提高了程序的执行效率。

## 21.fork 与system调用的区别？

fork 和 system 是两个常用的系统调用，用于进程创建和管理，它们有不同的用途和行为：

1. fork：创建一个新的子进程，该子进程是调用进程的副本。子进程继承了父进程的地址空间、文件描述符等资源，但有独立的进程ID。适用于多进程编程，需要**手动管理进程间的通信和同步**。
2. system：执行一个命令字符串，通常是一个外部程序。system 调用会创建一个子进程来运行指定的命令，**父进程等待子进程完成**。**适用于需要在程序中执行外部命令或脚本的场景**，简化了执行外部命令的过程，但缺乏对新进程的细粒度控制。

# 二、内存管理

## 1.用户空间分布

![image-20240501144037882](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012010228.png)

堆和文件映射段的内存是动态分配的，例如malloc和mmap。

## 2. 什么是虚拟内存？

1. 虚拟内存使用了空分复用技术，将物理内存抽象为地址空间，**每个进程都有自己的地址空间**。
2. 地址空间的**页**被映射到物理内存，地址空间的页不需要全部在物理内存中，使用到一个没有在物理内存的页时，触发缺页中断：如果物理内存没满就将所需页从磁盘加载到物理内存页。如果物理内存已满，执行**页面置换算法**，将该页置换到物理内存中。
3. 虚拟内存地址通过CPU芯片中的**内存管理单元**转换变成物理地址。

1.1缺页异常(缺页中断)

缺页中断与普通中断的区别

1. 缺页中断在指令执行期间产生和处理中断信号，而一般中断在一条指令执行完成后检查和处理中断信号。
2. 缺页中断返回该指令的开始重新执行该指令，而一般中断返回回到该指令的下一个指令执行。 

执行缺页中断处理函数-处理缺页异常

1. 在物理内存中找空闲页，如果找到空闲页，就把页面换入到物理内存中
2. 如果物理内存没有空闲页就执行页面置换算法。

1.2页面置换算法

​	当出现缺页异常，需调⼊新页面而内存已满时，选择被置换的物理页面。

1. 最佳页面置换算法(OPT)

   置换在**未来最长时间不访问的页面**,可以保证最低的缺页率。实际的进程执行过程中无法预知每个页面的下一次访问时间，所以最佳页面置换算法无法实现，但是**可以用来衡量算法的效率**，与OPT越接近越好。

2. 先进先出置换算法(FIFO)

   选择**在内存中驻留时间最长**的页面进行置换。

   FIFO的性能较差，因为较早调入的页面往往是常访问的页。

3. 最近最久未使用的置换算法(LRU)

   **将最近最少使用的页面进行置换**。在内存中维护一个所有页面的链表，最近最多使用的页面在表头，最近最少使用的页面在表尾。每次内存访问都要更新整个链表，开销较大。复杂度高

4. 时钟页面置换算法(Lock) **默认使用这个算法**

   把所有页面保存在一个环形链表，指针指向最老的页面，发生缺页中断，首先检查指针指向的页面。每个页面有个访问字段，表示最近是否访问过，如果是1就改为0，如果是0就换出。

5. 最不常用置换算法(LFU)

   选择**访问次数最少的页面换出**。每个页面设置一个访问计数器，访问的时候+1。

## 2.1虚拟内存的目的是什么？

1. **扩展物理内存**：虚拟内存将物理内存扩展为更大的逻辑内存，使程序可以在有限的物理内存下运行更大的程序，而无需将每一页都映射到物理内存中。
2. **实现内存隔离**：每个进程拥有独立的虚拟地址空间，确保进程之间的内存访问安全且互不干扰。虚拟内存提供了硬件层的内存保护，防止进程间不合法的内存访问
3. **简化内存管理**：虚拟内存提供了一个抽象的内存模型，使得程序员可以使用线性的虚拟地址空间，而不必关心物理内存的实际分布。
4. **内存权限管理**：虚拟内存允许操作系统为每个页面设置不同的访问权限（如只读、可读写、不可执行等）。这种权限控制提高了系统的安全性。例如，防止栈溢出攻击

## 3.Linux内存管理

逻辑地址[段:偏移]--段式内存管理-->线性地址/虚拟地址--页式内存管理-->物理地址。

程序使用的地址叫做逻辑地址。

X86 CPU先段式映射，然后才能进行页式映射。Linux中使段式映射的过程实际不起作用。Linux系统中每个段都是从0地址开始的整个4GB虚拟空间，所有的段的起始地址都一样。**相当于程序使用了虚拟地址，屏蔽了处理器汇总逻辑地址的概念，段只被用于访问控制和内存保护**。

### 1.段式内存管理

1. 段选择子：段内偏移。段选择子保存在段寄存器，段寄存器中有段描述符在段描述符表中的**索引值**、TI。TI表示了**段描述符表**在GDT还是LDT。GDT的地址在GDTR寄存器，LDT的地址在LDTR寄存器。根据索引找到段描述符。

2. 段描述符。8字节的一个表，有段基址。根据段描述符中的段基址与段内偏移得到线性地址。

3. 缺点：

   1. 外部内存碎片

      程序释放了一段内存，产生了多个不连续的小物理内存，导致新程序无法被装载。(**解决方案**：操作系统可以通过整理和移动内存内容，合并小的内存空闲块，使其变为一个连续的大块。)

   2. 内存交换效率低

      将外部内存碎片中间的进程占用内存写到硬盘，再读回来，让原本的碎片合并。硬盘访问速度比内存慢太多，很耗费时间。

   3. 内存浪费：程序所有内存被装载到了物理内存，但是程序的有部分内存不是常用的，这会导致内存的浪费。

### 2.页式内存管理

将虚拟内存和物理地址切成固定大小(页：page)，linux中一般为4KB，两者通过页表完成映射。页表储存在内存管理单元中。

#### 1.基本过程 

页表基址寄存器PTBR存放页表在物理内存中的起始地址。页表起始地址存放在PCB中，进程被调度这个信息就放到了PTBR中。

虚拟地址分为两部分：页号、页内偏移。页号作为页表的索引，页内偏移与页表项(PTE)中的基地址(页框号*页大小)组合形成物理内存地址。

1. 虚拟内存地址切分为页号和偏移量。判断页号是否越界。4kb页(2^12)的偏移量是32位线性地址的低12位.

2. 根据页号，从页表中查询对应的页表项。页表项中分为控制位(有效位)和物理页框号。

3. 页表项的有效位为1，则得到物理页基地址，与页内偏移组合得到物理地址。如果有效位为0就是发生了缺页异常。

缺陷：

1. 32位环境下，一个进程的页表要占据4MB的内存，进程多了就耗费太多的存储空间。因此有了多级页表(一般是2级)。
2. 内部内存碎片：分配的一页用不完，剩下的部分其他程序用不了。(解决方案：使用内存池可以减少频繁的内存分配和释放，从而避免碎片的产生。)

#### 2.多级页表(二级页表)

一级页表1024(2^10)个页目录项(PDE)，每个表项记录了一个二级页表(2^10个表项PTE)，一级页表覆盖到了全部虚拟地址空间，二级页表在需要时创建。以此达到了节约空间的目的。一个32为的线性地址，高十位做PDE的索引，中十位做PTE的索引，低十二位做偏移地址。

#### 3.TLB

**程序有局部性**，在一段时间整个程序执行仅限于程序中的某一部分，所以访问的存储空间也局限于某个内存区域。所以将常用的页表项放入缓存中，这个缓存就是TLB(快表)。

## 4.为什么分页选4KB？

1. **内存管理**: 4KB页面大小在减少内存碎片和保持合理页表大小之间取得了良好的平衡。
2. **性能**: 4KB页面大小适中，既能减少缺页异常的频率，提高内存访问性能，又不会导致过多的内存浪费。
3. 4KB页面大小满足大多数应用程序的内存需求，提供了良好的灵活性和内存利用率。

## 5.有快表和没有快表，有什么区别？

有快表可以查询快表,直接访问内存地址。一次内存访问。

没有快表要在内存中先找页表，然后才能访问内存地址，两次访问内存。

## 7.系统有快表，那么地址的转换过程变成什么样？

转换过程由MMU计算。根据虚拟地址得到页号+页内偏移量。页号与快表中的页号比较。

1. 找到匹配的页号，则是快表命中，直接从中取出该页对应的页框号，得到物理内存基址与页内偏移量拼接形成物理地址。
2. 快表中没有匹配的页号，则需要访问内存中的页表。
3. 找到对应的页表项，根据页表项中的物理页框号找到物理页地址，再加上页内偏移量拼接形成物理地址。

在找到页表项后，应同时将其存入快表，以便后面的再次访问。由于局部性原理，一般命中率在90%。

## 8.什么是逻辑地址，和物理地址有什么区别？

逻辑地址是程序在运行时使用的地址。操作系统通过页表机制,建立逻辑地址到物理地址的映射关系。页表机制允许程序使用连续的逻辑地址空间,实际物理内存可以是不连续的。

## 9.在执行malloc申请内存的时候，操作系统是怎么做的？

malloc是C库的函数，在申请内存的时候会有两种方式向操作系统申请堆内存：

1. 通过brk()系统调用从堆分配内存。

   将堆顶指针向高地址移动，获得新的内存空间。当开辟的空间小于 128K 时，调用 brk()函数，malloc 的底层实现是系统调用函数 brk()，其主要移动指针 _enddata(此时的 _enddata 指的是 Linux 地址空间中堆段的末尾地址，不是数据段的末尾地址)

2. 通过mmap系统调用在文件映射区域分配内存。

   当开辟的空间大于 128K 时，mmap()系统调用函数来在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟。

这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。

brk分配的内存需要等到高地址内存释放以后才能释放（例如，在B释放之前，A是不可能释放的，因为只有一个_edata 指针，这就是内存碎片产生的原因，外部内存碎片），而mmap分配的内存可以单独释放.

## 10.动态分区匹配算法

用于实现内存管理系统中的动态内存分配策略（一个进程需要内存）

1. 首次适配算法(效果比较好)

   从空闲内存表的头部开始搜索，找到第一个足够大的空闲分区来满足请求。复杂度为O(1)，但可能在内存开始部分导致内存碎片化。

2. 最佳适配算法

   从空闲分区列表中找到最小但足够大的空闲分区来满足请求。时间复杂度为O(n)，可以更好的利用内存，但是会产生更多的小碎片(外部碎片)。

3. 最坏适配算法

   从空闲分区列表中找到最大的空闲分区来满足请求。时间复杂度为O(n),可以减少内存碎片,但可能导致很多小的空闲分区无法使用。

4. 邻近适配算法

   类似于首次适配算法,但从上次搜索停止的位置开始查找。时间复杂度为O(1), 减少了内存开始部分的碎片化。可能会造成内存末尾产生碎片。


## 11. 内存交换和覆盖有什么区别？

内存交换是指在内存空间紧张时，将整个进程的地址空间(代码、数据、栈等)暂时转移到磁盘上,以释放物理内存空间。例如：在许多进程运行时经常发生缺页，就说明内存紧张，此时可以换出一些进程。

内存覆盖是指将一个进程的不同部分(如子程序、模块等)分别加载到物理内存的同一块区域,实现共享内存空间。打破了必须将一个进程的全部信息装入内存才能运行的限制。内存空间分成固定区和若干覆盖区，活跃的部分放在固定区。

## 12. 内存抖动

刚换出的页又要换入内存，刚换入的页又要换出磁盘，频繁的页面调度导致的行为称为抖动、颠簸。主要原因是进程频繁访问的页面数目高于可用的物理块数。

## 13. 内存换出时，有哪些进程被优先考虑？

1. 阻塞进程。2.优先级低的进程。

## 14.常见的内存分配方式

1. 静态存储区域分配：编译的时候分配好的，全局变量，静态变量。
2. 栈上分配：执行函数时的局部变量，函数参数。自动分配，容量有限。
3. 堆上分配：动态分配。大小灵活，需要手动管理
4. 内存池分配：预先分配固定大小的内存块，提高内存分配和释放的效率，减少碎片。

# 文件系统

## 1.文件的权限怎么理解？

Linux 文件和目录权限通过 **所有者**、**组用户** 和 **其他用户** 的 **读（r）**、**写（w）**、**执行（x）** 权限来控制。

权限可以用 **符号表示法** 或 **数字表示法** 来表示和修改。

使用 `ls -l` 查看文件权限，使用 `chmod` 修改权限，使用 `chown` 修改文件所有者和组。

## 2.文件系统的基本组成

linux下一切皆文件。除了文件和目录，块设备、套接字、管道，都是文件系统管理的。

每个文件有两个数据结构：

1. 索引节点(inode) inode里有权限、时间、块指针、

   记录文件的元信息，比如inode编号、文件大小、访问权限、创建修改时间、数据在磁盘的位置(块指针)、间接块索引表指针。等。索引节点是文件的唯一标识，一一对应，索引节点也存储在磁盘。

2. 目录项(数据结构，在内存)

   用来记录文件的名字、索引节点指针以及和其他目录项的层级关联关系。多个目录项关联起来会形成目录结构，目录项由内核维护，存储在内存中。

   目录项和索引节点的关系是多对一。

目录也是文件，用索引节点标识，目录文件在磁盘中保存子目录或者文件。

磁盘最小单位是扇区，文件系统将多个扇区组成一个逻辑块(4K)，一次性读8个扇区。

![image-20240918220646808](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012011842.png)

超级块：存储文件系统的详细信息，块个数、块大小、空闲块。

索引节点区：存储索引节点

数据块区：存储具体数据

超级块当文件系统挂载时放进内存，索引节点在文件访问时放入内存。

用户层和文件系统之间引入了虚拟文件系统。虚拟文件系统定义了数据结构和接口。文件系统要挂载到某个目录才能正常使用，启动时，linux将文件系统挂载到根目录。

文件系统针对分区进行管理，每个分区有自己的inode数组

每个分区：操作系统引导块、超级块、空闲块的位图、 inode位图、 inode数组、根目录、空闲块区域

## 3.文件创建的底层过程？

1. 查找空闲 inode，通过 inode 位图标记为已使用。
2. 在 inode 数组中初始化 inode，并设置文件的元数据。
3. 如果需要，为文件分配空闲数据块，更新空闲块位图。
4. 在父目录的目录项中为新文件添加条目，将文件名与 inode 关联。
5. 更新超级块、空闲块位图、inode 位图等文件系统的元数据。

## 4.文件访问的过程？页表发生的变化，怎么理解DMA？(应用访问一块磁盘上的数据需要哪些步骤？)

### 1.找数据块

1. 用户程序调用系统调用read，根据文件描述符访问文件。
2. 进程有自己单独的一套文件描述符，文件描述符和文件描述符表关联
3. 文件描述符表存储在PCB中，根据文件描述符(fd 表的下标)得到表项-打开文件表。打开文件表中有：文件的偏移量、文件访问模式、inode。
4. 根据打开文件表中的inode指针在inode缓存中找。
5. 如果没有，就从硬盘中将这个inode加载到缓存，并将inode指针指向它。
6. 根据inode中的数据块指针或者间接数据块指针找到数据块。

### 2.读到内存

1. 通过操作系统的 **I/O 子系统**，发起一个磁盘 I/O 请求。操作系统将请求交给磁盘驱动程序，驱动程序与具体的硬件接口交互，准备进行磁盘读取。

2. 当磁盘控制器收到读取请求时，它会利用 **DMA（Direct Memory Access）** 来执行数据传输。DMA 允许硬件设备直接与系统内存交换数据，而不需要 CPU 参与其中，减少了 CPU 的负载，提高了效率。

3. 操作系统中的**页表**将应用程序的虚拟地址空间映射到物理内存。当应用程序访问磁盘数据时，最终数据会被加载到物理内存中。此时，页表会进行更新，将虚拟地址映射到新的物理内存页上（即 DMA 传输的数据块所在的内存页）。

   **页表变化的具体过程**：

   1. 应用程序通过虚拟地址请求数据。
   2. 如果数据不在内存中，会发生**页面缺失**（Page Fault），操作系统将发起磁盘 I/O 请求。
   3. DMA 传输数据到物理内存，操作系统在页表中更新对应的虚拟地址到物理地址的映射。
   4. 当页表完成映射更新后，应用程序就可以通过虚拟地址访问数据了。

4. 当数据被成功读取到内存中，操作系统会将其传递回应用程序。此时，CPU 从内存中提取数据并将其交给应用程序使用。

## 5.文件的存储

根据文件的索引，使用inode管理文件。

![image-20241001201322214](https://cdn.jsdelivr.net/gh/dal-code/imageBed@master/202410012013364.png)

13个指针，10个指向数据块，第十一个是索引块指针，第十二个是二级索引块指针，第十三个是三级索引块指针。

# 网络编程

## 1. 什么是IO

IO就是内存与外部设备之间的交互(数据拷贝)。网络IO:网卡和内存之间的输入输出。磁盘IO:磁盘和内存的输入输出。

## 2.网络IO为什么会被阻塞？

1. 数据传输速度不均衡。发送方发送数据快于接收方处理数据的速度，接收方缓存满了，发送方IO阻塞。
2. 网络拥塞。数据包传输延迟或丢失，发送方IO阻塞。
3. 阻塞式IO操作。

## 3.IO模型有哪些

1. 同步IO：要求用户代码自行执行IO操作。
   1. 阻塞IO:阻塞等待数据准备好
   2. 非阻塞IO（与IO通知机制一起使用）
      1. IO复用：通过IO复用函数向内核注册事件，内核通过IO复用函数将就绪事件通知应用程序。IO复用本身是阻塞的，提高程序效率是因为可以监听多个IO事件。
      2. 信号驱动IO：使用信号（`signal`）通知进程I/O操作的就绪状态。当I/O操作准备好时，内核向进程发送一个信号，进程在收到信号后执行实际的I/O操作。
2. 异步IO：由内核执行IO操作并触发读写完成事件。

## 4.同步IO和异步IO

**同步**: 任务按顺序执行，程序在等待任务完成时会阻塞。适合简单的任务执行场景，但在等待时间较长时效率低。

**异步**: 异步 I/O 是指发起 I/O 操作后，程序不等待该操作完成，而是立即返回继续执行后续代码。当 I/O 操作完成时，系统会通过回调、事件通知等机制告知程序。适合高并发和I/O密集型任务，但编程复杂度较高。

数据未准备完时，代码的逻辑处理不同。

## 4.1怎么将同步IO变成异步IO

使用Linux的异步 I/O 接口，例如 `aio_read()` 和 `aio_write()`。你可以使用这些接口发起异步 I/O 操作，而不需要阻塞等待数据传输完成。I/O 操作完成后，可以通过回调或轮询来获取结果

## 5.阻塞和非阻塞

主要区别在于调用线程在等待 I/O 操作完成时的行为。阻塞IO会阻塞线程，直到操作完成。非阻塞IO会立即返回，无论事件是否发生。

数据未处理完成时，线程的状态不同。

## 6.什么是 BIO、NIO、AIO?

1. **BIO**（阻塞 I/O）适合简单、小规模并发场景。发起io的线程会阻塞。
2. **NIO**（非阻塞 I/O）适合高并发、大规模连接场景。事件驱动编程。
3. **AIO**（异步 I/O）提供最高效的 I/O 操作，适用于要求极高的性能和吞吐量的场景。

## 7.NIO和AIO的区别？

1. **是否需要主动检查 I/O 状态**；
2. 线程自己负责检查io操作准备好了没；线程不再管这个io，由操作系统管

## 8.IO复用: epoll、select、poll

IO复用让程序能够在同时等待多个文件描述符可读、可写或发生异常时，进行相应的处理。

select：兼容性好。缺点：select 使用固定长度的位图表示文件描述符集合，数量上限为 1024。①用3个集合保存监视的文件描述符②调用select前将整个文件描述符表传递给内核，存在**拷贝开销**，调用select内核返回文件描述符中有事件的子集。③轮询的方式检测是否就绪，复杂度为On。

```cpp
fd_set readfds; // 文件描述符集合
FD_ZERO(&readfds);       // 初始化文件描述符集合
FD_SET(sockfd, &readfds); // 将 sockfd 添加到集合中
// 等待事件发生 没有超时时间就阻塞等待，有超时时间到时间会返回0表示超时
select(sockfd + 1, &readfds, NULL, NULL, NULL); 
if (FD_ISSET(sockfd, &readfds)) {
    // sockfd 上有数据可读
}
```

poll：用动态数组以链表形式来组织一个事件集合，在select的基础上解决了数量上限。缺点：①还会受到系统文件描述符限制。②来回拷贝所有文件描述符

epoll：linux下的优化实现。①直接在内核创建事件表，减少了拷贝开销。②事件驱动：epoll_wait等待事件发生，有事件发生才传回fd。

```cpp
int epfd = epoll_create(5);       // 创建 epoll 实例
struct epoll_event ev, events[10]; // 定义事件结构
ev.events = EPOLLIN;               // 设置为输入事件
ev.data.fd = sockfd;  // 关联套接字
// 添加事件到 epoll 实例
epoll_ctl(epfd, EPOLL_CTL_ADD, sockfd, &ev); 
// 等待事件发生 第四个参数是超时时间：0表示立即返回，-1表示无限等待
int nfds = epoll_wait(epfd, events, 10, -1); 
// 遍历发生的事件，一个个处理
for (int i = 0; i < nfds; ++i) {
    if (events[i].data.fd == sockfd) {
        // sockfd 上有数据可读
    }
}
```

## 9.epoll详解

使用红黑树跟踪进程待检测的文件描述符，不需要来回拷贝事件集合。内核维护了链表记录就绪事件，有socket发生事件，通过回调函数内核会将其加入到就绪事件列表中，用epoll_wait函数返回。

水平触发(默认)：当 `epoll` 监控的文件描述符**一直处于就绪状态**（例如有数据可读或可写）时，`epoll_wait()` 调用每次都会通知应用程序文件描述符处于就绪状态，**直到该事件被处理**（即数据被完全读取或写入）。

边缘触发：`epoll` 只会通知应用程序一次，除非文件描述符状态再次变化。所以，如果应用程序在接到通知后没有处理所有数据，`epoll` 不会再次通知，应用程序可能会错过后续的可读或可写事件。
避免了重复通知，高负载下性能更好，但是必须保证收到通知后一次性处理完所有数据，通常配合非阻塞IO使用。阻塞IO可能会导致永远等待或者读不全数据。

```cpp
fcntl(fd, F_SETFL, O_NONBLOCK);
```

水平触发的稳定性好，不怕数据读不完。边缘触发的性能好，适用于高并发场景，需要配合非阻塞IO使用，要确保一次将数据读完。

### 边缘触发如何保证读取缓冲区所有内容？

使用循环将缓冲区中的所有数据读取出来。必须将缓冲区的内容都读出来。

```cpp
while (1) {
    bytes_read = read(fd, buf, sizeof(buf));
    if (bytes_read > 0) {
        // 处理读取的数据
    } else if (bytes_read == 0) {
        // 对端关闭连接
        close(fd);
        break;
    } else {
        if (errno == EAGAIN || errno == EWOULDBLOCK) {
            // 缓冲区没有更多数据可读
            break;
        } else {
            // 处理读取错误
            close(fd);
            break;
        }
    }
}
```

## 10.Reactor

Reactor模型的核心思想是将所有I/O操作（如读写事件、连接事件等）注册到一个事件分发器中，当某个事件就绪时，事件分发器会将事件通知给相应的处理器（处理器通常是回调函数或方法），由处理器执行具体的操作。

事件分发器：select poll epoll实现。事件处理器 ：线程

事件注册、事件监听、事件触发、事件处理、重复循环。

## 11.并发模式

1. 半同步半反应堆

   主线程使用 `epoll_wait` 等待客户端连接或 I/O 事件。当有新连接时，主线程通过 `accept` 接收连接，并将客户端的 socket 描述符添加到 `epoll` 事件监听列表。当客户端有读写事件时，socket 描述符会通过 `epoll` 被检测到，然后放入任务队列中。线程池中的工作线程从任务队列中获取待处理的 I/O 事件，并执行 I/O 操作和业务逻辑处理。

   缺点：工作队列中添加、取出需要加锁；

   总结：将 I/O 的监听与实际的处理分开，通过 `epoll` 进行异步事件的监听，而将同步处理部分（包括 I/O 操作和业务逻辑）交给线程池。

2. 高效的半同步半异步

   主线程监听socket，接收客户端连接之后，socket直接派发给某个工作线程（线程间通信）。没有请求队列。

# 四、其他

## 1.对虚拟技术的了解？

1. 时分复用技术

   多个进程能在同一个处理器上并发执行时分复用技术，让每个进程轮流占用处理器，每次只执行一小个时间片并快速切换。

2. 空分复用技术

   虚拟内存使用了空分复用技术，将物理内存抽象为地址空间，每个进程都有各自的地址空间。地址空间的页被映射到物理内存，地址空间的页并不需要全部在物理内存中，当使用到一个没有在物理内存的页时，执行页面置换算法，将该页置换到内存中。

## 2.为什么分为用户态和内核态？

在CPU的所有指令中，有一些指令是非常危险的，如果错用，将导致整个系统崩溃。比如：清内存、设置时钟等。

CPU将指令分为特权指令和非特权指令，对于那些危险的指令，只允许操作系统及其相关模块使用，普通的应用程序只能使用那些不会造成灾难的指令。

本质意义是进行权限保护。 限定用户的程序不能乱搞操作系统，如果人人都可以任意读写任意地址空间软件管理便会乱套

## 3.内核态和用户态？

内核态与用户态是操作系统的两种运行级别,当程序运行在3级特权级上时，就可以称之为运行在用户态，因为这是最低特权级，是普通的用户进程运行的特权级，大部分用户直接面对的程序都是运行在用户态；当程序运行在0级特权级上时，就可以称之为运行在内核态。

1. 用户态：不能直接使用系统资源，也不能改变CPU的工作状态，只能访问这个用户程序自己的存储空间。
2. 内核态：系统中既有操作系统的程序，也有普通用户程序，为了安全性和稳定性，操作系统的程序不能随便访问，这就是内核态。执行操作系统的程序就要切到内核态执行。内核态可以使用计算机的所有资源。

## 4.什么时候发成用户态和内核态的切换？

系统调用、中断：外部中断需要进入内核态执行中断处理程序

异常：发生了异常，会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。

## 5.什么是系统调用？

**系统调用**（System Call）是操作系统内核提供给用户程序的一种接口，通过它，用户态的程序可以请求内核态执行某些特权操作。系统调用是用户程序与操作系统之间的重要桥梁。

1. 用户程序通过调用标准库（如 `glibc`）中的接口（如 `open`, `read`, `write`）发起系统调用。
2. 标准库中的实现将系统调用号放入指定寄存器中（如 x86_64 的 `rax` 寄存器）并通过寄存器传递参数。
3. 32 位系统使用 `int 0x80`，64 位系统使用 `syscall` 指令，通过陷入机制进入内核态。
4. 内核通过系统调用号在系统调用表中查找相应的系统调用处理函数，从寄存器获取参数，并执行相应的内核功能。
5. 执行完成后，内核将结果保存在指定的寄存器中，并通过 `sysret` 指令返回用户态程序。如果系统调用失败，返回负数表示错误代码。
6. 用户态程序从返回的寄存器中获取系统调用的返回结果，并进行相应的处理。

## 6.怎么减少内核态和用户态的切换？

1. 优化代码，避免不必要的系统调用
2. **使用零拷贝技术：**减少数据在用户态和内核态之间的复制。
3. **使用高效的I/O多路复用：**使用 epoll 等高效的I/O多路复用技术，减少阻塞I/O带来的切换。
4. 优化调度和锁机制，减少任务之间的切换次数。
